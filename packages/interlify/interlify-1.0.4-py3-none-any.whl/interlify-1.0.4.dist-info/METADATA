Metadata-Version: 2.2
Name: interlify
Version: 1.0.4
Summary: A Python client for the Interlify API
Home-page: https://github.com/EricZhou0815/Interlify-python-sdk
Author: Interlify
Author-email: eric.zhoul@interlify.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
Requires-Dist: requests
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# Interlify Client

A Python client for the [Interlify API](https://www.interlify.com).

## Installation

Install via pip:

```bash
pip install interlify
```

Usage:

```python
from openai import OpenAI
from interlify import Interlify


client = OpenAI()

# Initialize the client
interlify = Interlify(
    api_key="YOUR_API_KEY", 
    project_id="YOUR_PROJECT_ID", 
    auth_headers=[
        {"Authorization": "Bearer YOUR_TOKEN"}
        ]
    )

# Prepare tools
tools = client.get_tools()

completion = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "What is the weather like in Paris today?"}],
    # Use tools
    tools=tools
)

response_message = response.choices[0].message
tool_calls = response_message.tool_calls

messages.append(response_message)


for tool_call in tool_calls:
    function_name = tool_call.function.name
 
    function_args = json.loads(tool_call.function.arguments)

    # Call the tool using interlify
    function_response = interlify.call_tool(function_name, function_args)

    messages.append(
        {
            "role": "tool",
            "content": str(function_response),
            "tool_call_id": tool_call.id,
        }
    )

final_response = client.chat.completions.create(
    model=model, messages=messages, tools=tools, tool_choice="auto"
)

print(final_response.choices[0].message.content)

```



## Work with OpenAI Agent SDK

OpenAI just released its [Agent SDK](). The Agents SDK is designed to be highly flexible, allowing you to model a wide range of LLM workflows including deterministic flows, iterative loops, and more.

Interlify's latest version supports OpenAI agent for tools calling, which makes integrating your APIs or services to the modern agent capability in a flash!

Here is the code:

```python
import asyncio
import os
from dotenv import load_dotenv

from openai import AsyncOpenAI

from agents import (
    Agent,
    OpenAIChatCompletionsModel,
    Runner,
    set_tracing_disabled,
    FunctionTool
)

from interlify import Interlify

load_dotenv()

# Set these variables in your .env file 
BASE_URL = os.getenv("BASE_URL") or ""
API_KEY = os.getenv("API_KEY") or ""
MODEL_NAME = os.getenv("MODEL_NAME") or ""
INTERLIFY_API_KEY = os.getenv("INTERLIFY_API_KEY") or ""
PROJECT_ID = os.getenv("PROJECT_ID") or ""
ACCESS_TOKEN = os.getenv("ACCESS_TOKEN") or ""


if not BASE_URL or not API_KEY or not MODEL_NAME or not INTERLIFY_API_KEY or not PROJECT_ID or not ACCESS_TOKEN:
    raise ValueError(
        "Please set BASE_URL, API_KEY, MODEL_NAME, INTERLIFY_API_KEY, PROJECT_ID, ACCESS_TOKEN via env var or code."
    )

# works for non-openai model as well
client = AsyncOpenAI(base_url=BASE_URL, api_key=API_KEY)
# disable tracing if you are using non-openai model
set_tracing_disabled(disabled=True)

# Initialize the client
interlify = Interlify(
    api_key=INTERLIFY_API_KEY,
    project_id=PROJECT_ID,
    auth_headers=[{"Authorization": f"Bearer {ACCESS_TOKEN}"}],
)


# Prepare tools for agent: convert tools to FunctionTool format that agent can use
agent_tools = [
    FunctionTool(
        name=tool["name"],
        description=tool["description"],
        params_json_schema=tool["function"]["parameters"]["properties"],
        on_invoke_tool=tool["tool_function"],
    )
    for tool in interlify.get_tools()
]

async def main():

    agent = Agent(
        name="Assistant",
        instructions="You are a shoe shop assistant.",
        model=OpenAIChatCompletionsModel(model=MODEL_NAME, openai_client=client),
        tools=agent_tools,
    )

    result = await Runner.run(agent, "please update the price of the second shoe to 100.")
    print(result.final_output)


if __name__ == "__main__":
    asyncio.run(main())

```

That's it!

To setup the tools and projects, please visit to [interlify](https://www.interlify.com) website. 
