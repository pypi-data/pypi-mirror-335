{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook related\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 01:07:45.437\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36mget_train_val_locs\u001b[0m:\u001b[36m285\u001b[0m - \u001b[33m\u001b[1mn_val_locs is greater than the maximum number of samples available. Setting n_val_locs to 7336\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7336, 28)\n"
     ]
    }
   ],
   "source": [
    "from dataset import get_train_val_locs\n",
    "\n",
    "train_locs, val_locs = get_train_val_locs(n_val_locs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzanaga/miniconda3/envs/eo/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/dzanaga/miniconda3/envs/eo/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "\u001b[32m2024-11-04 15:55:33.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mevotrain.v2\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mFound dataset at /vitodata/vegteam/projects/evoland/training/evotrain_v2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from dataset import EvoNetV1Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EvoNetV1Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats, feats_head, target = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([36, 128, 128]),\n",
       " torch.Size([9, 128, 128]),\n",
       " torch.Size([9, 128, 128]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape, feats_head.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"configs/lcm10-unet-base-v06_debug_mep.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Conv2d(16, 20, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
      "Initializing Conv2d(16, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
      "Initializing Conv2d(16, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "Initializing Conv2d(16, 20, kernel_size=(1, 1), stride=(1, 1), padding_mode=reflect)\n",
      "Initializing Linear(in_features=89, out_features=300, bias=True)\n",
      "Initializing Linear(in_features=300, out_features=200, bias=True)\n",
      "Initializing Linear(in_features=200, out_features=200, bias=True)\n",
      "Initializing Linear(in_features=200, out_features=100, bias=True)\n",
      "Initializing Linear(in_features=100, out_features=9, bias=True)\n"
     ]
    }
   ],
   "source": [
    "net = Net(**config[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = net(feats.unsqueeze(0), feats_head.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzanaga/miniconda3/envs/eo/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from dataset import get_train_val_dataloaders\n",
    "\n",
    "train_loader, val_loader, train_dataset, val_dataset = (\n",
    "    get_train_val_dataloaders(\"configs/lcm10-unet-base-v06_debug_mep.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzanaga/miniconda3/envs/eo/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ybatch = net(batch[0], batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from evotrain.v2 import EvoTrainV2Dataset\n",
    "\n",
    "evo_ds = EvoTrainV2Dataset()\n",
    "v3_locs = evo_ds.locs\n",
    "v3_locs = v3_locs[v3_locs.aux]  # discard locs without aux tifs. to check\n",
    "\n",
    "group0 = v3_locs[v3_locs.group == 0]\n",
    "train_locs0 = group0[\n",
    "    (group0.lab_50 > 0.05) | (group0.lab_70 > 0.05) | (group0.lab_20 > 0.05)\n",
    "].location_id.values\n",
    "\n",
    "group1 = v3_locs[v3_locs.group == 1]\n",
    "train_locs = group1.location_id.values\n",
    "train_locs = np.concatenate([train_locs0, train_locs])\n",
    "\n",
    "\n",
    "# group2 = v3_locs[v3_locs.group == 2].sample(n=n_val_locs, random_state=42)\n",
    "# val_locs = group2.location_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lab_10     0.216607\n",
       "lab_20     0.188427\n",
       "lab_30     0.245537\n",
       "lab_40     0.097034\n",
       "lab_50     0.040324\n",
       "lab_60     0.069956\n",
       "lab_70     0.006992\n",
       "lab_80     0.076982\n",
       "lab_90     0.032144\n",
       "lab_95     0.007721\n",
       "lab_100    0.018275\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_cols = [col for col in v3_locs.columns if \"lab\" in col]\n",
    "\n",
    "v3_locs[v3_locs.location_id.isin(train_locs)][lab_cols].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8133"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_locs0 = group0[\n",
    "    (group0.lab_50 > 0.05) | (group0.lab_70 > 0.05) | (group0.lab_20 > 0.72)\n",
    "].location_id.values\n",
    "train_locs0.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group2 = v3_locs[v3_locs.group == 2]\n",
    "lab_cols = [col for col in group2.columns if \"lab\" in col]\n",
    "\n",
    "val_locs = []\n",
    "for lab in lab_cols:\n",
    "    if lab in [\"lab_10\", \"lab_30\"]:\n",
    "        continue\n",
    "    g = group2[group2[lab] > 0.30]\n",
    "    val_locs += g.sample(min(1000, len(g))).location_id.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7581"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzanaga/miniconda3/envs/eo/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/dzanaga/miniconda3/envs/eo/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "\u001b[32m2024-11-06 01:04:05.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mevotrain.v2\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mFound dataset at /vitodata/vegteam/projects/evoland/training/evotrain_v2\u001b[0m\n",
      "\u001b[32m2024-11-06 01:04:05.774\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36mget_train_val_locs\u001b[0m:\u001b[36m282\u001b[0m - \u001b[33m\u001b[1mn_val_locs is greater than the maximum number of samples available. Setting n_val_locs to 7580\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_train_val_locs\n\u001b[0;32m----> 3\u001b[0m train_locs, val_locs \u001b[38;5;241m=\u001b[39m \u001b[43mget_train_val_locs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_val_locs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/users/Private/dzanaga/repos/evotrain/src/evotrain/train/lcm10/v002/dataset.py:287\u001b[0m, in \u001b[0;36mget_train_val_locs\u001b[0;34m(locs_scenario, n_val_locs)\u001b[0m\n\u001b[1;32m    281\u001b[0m     n_val_locs \u001b[38;5;241m=\u001b[39m max_val_samples\n\u001b[1;32m    282\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_val_locs is greater than the maximum number of samples available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting n_val_locs to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_val_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m val_locs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 287\u001b[0m     \u001b[43mgroup2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgroup2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_locs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_val_locs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;241m.\u001b[39mlocation_id\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    290\u001b[0m )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_locs, val_locs\n",
      "File \u001b[0;32m~/miniconda3/envs/eo/lib/python3.10/site-packages/pandas/core/generic.py:6029\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   6026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6027\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[0;32m-> 6029\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6030\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   6032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[0;32m~/miniconda3/envs/eo/lib/python3.10/site-packages/pandas/core/sample.py:152\u001b[0m, in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m    153\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    154\u001b[0m )\n",
      "File \u001b[0;32mmtrand.pyx:1000\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "from dataset import get_train_val_locs\n",
    "\n",
    "train_locs, val_locs = get_train_val_locs(n_val_locs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
