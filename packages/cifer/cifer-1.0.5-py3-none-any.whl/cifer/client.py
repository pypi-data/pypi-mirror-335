import requests
import base64
import json
import tensorflow as tf
import numpy as np
import os
from cifer.config import CiferConfig  # ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ Config

class CiferClient:
    def __init__(self, encoded_project_id, encoded_company_id, encoded_client_id, base_api=None, dataset_path=None, model_path=None):
        """
        ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á Client
        """
        self.config = CiferConfig(
            encoded_project_id, 
            encoded_company_id, 
            encoded_client_id, 
            base_api, 
            dataset_path, 
            model_path
        )
        self.api_url = self.config.base_api
        self.dataset_path = self.config.dataset_path
        self.model_path = self.config.model_path

        # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
        self.model = self.load_model()

    def load_dataset(self):
        """
        ‡πÇ‡∏´‡∏•‡∏î dataset ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å API
        """
        if os.path.exists(self.dataset_path):
            print(f"üìÇ Loading dataset from {self.dataset_path} ...")
            data = np.load(self.dataset_path)
            return data["train_images"], data["train_labels"]
        else:
            print("‚ùå Dataset not found! Please check dataset path.")
            return None, None

    def load_model(self):
        """
        ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
        """
        if os.path.exists(self.model_path):
            print(f"üìÇ Loading model from {self.model_path} ...")
            return tf.keras.models.load_model(self.model_path)
        else:
            print("‚ùå Model file not found, attempting to download...")
            return self.download_model()

    def download_model(self):
        """
        ‡∏î‡∏∂‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
        """
        url = f"{self.api_url}/get_latest_model/{self.config.project_id}"
        response = requests.get(url)

        try:
            data = response.json()
            if data.get("status") == "success":
                model_data = base64.b64decode(data["model"])
                with open(self.model_path, "wb") as f:
                    f.write(model_data)
                print(f"‚úÖ Model downloaded successfully: {self.model_path}")
                return tf.keras.models.load_model(self.model_path)
            else:
                print("‚ùå No valid model received. Creating new model...")
                return self.create_new_model()
        except Exception as e:
            print(f"‚ùå ERROR: {e}")
            return self.create_new_model()

    def create_new_model(self):
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î
        """
        print("üõ†Ô∏è Creating new model...")
        model = tf.keras.Sequential([
            tf.keras.layers.Flatten(input_shape=(28, 28)),
            tf.keras.layers.Dense(128, activation="relu"),
            tf.keras.layers.Dense(10, activation="softmax")
        ])
        model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])
        model.save(self.model_path)
        print(f"‚úÖ New model created and saved at {self.model_path}")
        return model

    def train_model(self):
        print("üöÄ Training model...")

        # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î dataset
        train_images, train_labels = self.load_dataset()
        
        if train_images is None or train_labels is None:
            print("‚ùå ERROR: Dataset is empty or corrupted!")
            return None, None

        # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if self.model is None:
            print("‚ùå ERROR: Model not loaded! Cannot train.")
            return None, None

        self.model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])
        history = self.model.fit(train_images, train_labels, epochs=1, batch_size=32, verbose=1)

        accuracy = history.history.get("accuracy", [None])[-1]
        if accuracy is None:
            print("‚ùå ERROR: Accuracy not found in training history!")
            return None, None

        return self.model, accuracy  # ‚úÖ ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ model ‡πÅ‡∏•‡∏∞ accuracy

    def upload_model(self, model, accuracy):
        """
        ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
        """
        model.save(self.model_path)
        with open(self.model_path, "rb") as f:
            model_data = f.read()

        files = {"model_file": (self.model_path, model_data)}
        data = {
            "project_id": self.config.project_id,
            "client_id": self.config.client_id,
            "accuracy": accuracy
        }

        response = requests.post(f"{self.api_url}/upload_model", files=files, data=data)
        if response.status_code == 200:
            print("‚úÖ Model uploaded successfully!")
        else:
            print("‚ùå Upload failed:", response.text)

    def run(self):
        print("üöÄ Starting Federated Learning Cycle...")

        # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö dataset ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°
        if not os.path.exists(self.dataset_path):
            print(f"‚ùå Dataset not found at {self.dataset_path}. Please check your dataset path.")
            return  # ‚úÖ ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ dataset

        model, accuracy = self.train_model()
        
        # ‚úÖ ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô `TypeError: cannot unpack non-iterable NoneType`
        if model is None or accuracy is None:
            print("‚ùå ERROR: Training failed. Please check logs.")
            return

        print(f"‚úÖ Training complete! Accuracy: {accuracy:.4f}")
        self.upload_model(model, accuracy)
