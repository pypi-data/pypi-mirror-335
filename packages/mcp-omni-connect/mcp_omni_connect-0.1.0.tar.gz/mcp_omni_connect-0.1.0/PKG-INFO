Metadata-Version: 2.4
Name: mcp-omni-connect
Version: 0.1.0
Summary: Universal MCP Client with multi-transport support and LLM-powered tool routing
Project-URL: Homepage, https://github.com/Abiorh001/mcp_omni_connect
Project-URL: Repository, https://github.com/Abiorh001/mcp_omni_connect.git
Project-URL: Issues, https://github.com/Abiorh001/mcp_omni_connect/issues
Author-email: Abiola Adeshina <abioladedayo1993@gmail.com>
License: MIT License
        
        Copyright (c) 2025 Abiola  Adeshina
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
License-File: LICENSE
Keywords: ai,cli,llm,mcp,smithery
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.12
Requires-Dist: anyio>=4.2.0
Requires-Dist: httpx-sse>=0.4.0
Requires-Dist: httpx>=0.26.0
Requires-Dist: pydantic>=2.6.0
Requires-Dist: rich>=13.7.0
Requires-Dist: websockets>=12.0
Description-Content-Type: text/markdown

# üöÄ MCPOmni Connect - Universal Gateway to MCP Servers

MCPOmni Connect is a powerful, universal command-line interface (CLI) that serves as your gateway to the Model Context Protocol (MCP) ecosystem. It seamlessly integrates multiple MCP servers, AI models, and various transport protocols into a unified, intelligent interface.

## ‚ú® Key Features

### üîå Universal Connectivity
- **Multi-Protocol Support**
  - Native support for stdio transport
  - Server-Sent Events (SSE) for real-time communication
  - Docker container integration
  - NPX package execution
  - Extensible transport layer for future protocols

### üß† AI-Powered Intelligence
- **Advanced LLM Integration**
  - Seamless OpenAI model integration
  - Dynamic system prompts based on available capabilities
  - Intelligent context management
  - Automatic tool selection and chaining

### üí¨ Prompt Management
- **Advanced Prompt Handling**
  - Dynamic prompt discovery across servers
  - Flexible argument parsing (JSON and key-value formats)
  - Cross-server prompt coordination
  - Intelligent prompt validation
  - Context-aware prompt execution
  - Real-time prompt responses
  - Support for complex nested arguments
  - Automatic type conversion and validation

### üõ†Ô∏è Tool Orchestration
- **Dynamic Tool Discovery & Management**
  - Automatic tool capability detection
  - Cross-server tool coordination
  - Intelligent tool selection based on context
  - Real-time tool availability updates

### üì¶ Resource Management
- **Universal Resource Access**
  - Cross-server resource discovery
  - Unified resource addressing
  - Automatic resource type detection
  - Smart content summarization

### üîÑ Server Management
- **Advanced Server Handling**
  - Multiple simultaneous server connections
  - Automatic server health monitoring
  - Graceful connection management
  - Dynamic capability updates

## üèóÔ∏è Architecture

### Core Components
```
MCPOmni Connect
‚îú‚îÄ‚îÄ Transport Layer
‚îÇ   ‚îú‚îÄ‚îÄ Stdio Transport
‚îÇ   ‚îú‚îÄ‚îÄ SSE Transport
‚îÇ   ‚îî‚îÄ‚îÄ Docker Integration
‚îú‚îÄ‚îÄ Session Management
‚îÇ   ‚îú‚îÄ‚îÄ Multi-Server Orchestration
‚îÇ   ‚îî‚îÄ‚îÄ Connection Lifecycle Management
‚îú‚îÄ‚îÄ Tool Management
‚îÇ   ‚îú‚îÄ‚îÄ Dynamic Tool Discovery
‚îÇ   ‚îú‚îÄ‚îÄ Cross-Server Tool Routing
‚îÇ   ‚îî‚îÄ‚îÄ Tool Execution Engine
‚îî‚îÄ‚îÄ AI Integration
    ‚îú‚îÄ‚îÄ LLM Processing
    ‚îú‚îÄ‚îÄ Context Management
    ‚îî‚îÄ‚îÄ Response Generation
```

## üöÄ Getting Started

### Prerequisites
- Python 3.12+
- OpenAI API key
- UV package manager (recommended)

### Quick Start

1. **Installation**
   ```bash
   # Clone the repository
   git clone https://github.com/Abiorh001/mcp_connect.git
   cd mcp_connect

   # Create and activate virtual environment
   uv venv
   source .venv/bin/activate

   # Install dependencies
   uv sync
   ```

2. **Configuration**
   ```bash
   # Set up environment variables
   echo "OPENAI_API_KEY=your_key_here" > .env

   # Configure your servers in servers_config.json
   ```

### Server Configuration Examples

```json
{   
    "LLM": {
        "model": "gpt-4o-mini",
        "temperature": 0.5,
        "max_tokens": 5000,
        "top_p": 0
    },
    "mcpServers": {
        "filesystem-server": {
            "command": "npx",
            "args": [
                "@modelcontextprotocol/server-filesystem",
                "/path/to/files"
            ]
        },
        "sse-server": {
            "type": "sse",
            "url": "http://localhost:3000/mcp",
            "headers": {
                "Authorization": "Bearer token"
            },
        },
        "docker-server": {
            "command": "docker",
            "args": ["run", "-i", "--rm", "mcp/server"]
        }
    }
}
```

## üéØ Usage

### Interactive Commands
- `/tools` - List all available tools across servers
- `/prompts` - View available prompts
- `/prompt:<name>/<args>` - Execute a prompt with arguments
  ```
  # Example: Weather prompt
  /prompt:weather/location=tokyo/units=metric
  
  # Alternative JSON format
  /prompt:weather/{"location":"tokyo","units":"metric"}
  ```
- `/resources` - List available resources
- `/resource:<uri>` - Access and analyze a resource
- `/debug` - Toggle debug mode
- `/refresh` - Update server capabilities

### Prompt Management
```bash
# List all available prompts
/prompts

# Basic prompt usage
/prompt:weather/location=tokyo

# Prompt with multiple arguments depends on the server prompt arguments requirements
/prompt:travel-planner/from=london/to=paris/date=2024-03-25

# JSON format for complex arguments
/prompt:analyze-data/{
    "dataset": "sales_2024",
    "metrics": ["revenue", "growth"],
    "filters": {
        "region": "europe",
        "period": "q1"
    }
}

# Nested argument structures
/prompt:market-research/target=smartphones/criteria={
    "price_range": {"min": 500, "max": 1000},
    "features": ["5G", "wireless-charging"],
    "markets": ["US", "EU", "Asia"]
}
```

### Advanced Prompt Features
- **Argument Validation**: Automatic type checking and validation
- **Default Values**: Smart handling of optional arguments
- **Context Awareness**: Prompts can access previous conversation context
- **Cross-Server Execution**: Seamless execution across multiple MCP servers
- **Error Handling**: Graceful handling of invalid arguments with helpful messages
- **Dynamic Help**: Detailed usage information for each prompt

### AI-Powered Interactions
The client intelligently:
- Chains multiple tools together
- Provides context-aware responses
- Automatically selects appropriate tools
- Handles errors gracefully
- Maintains conversation context

## üîß Advanced Features

### Tool Orchestration
```python
# Example of automatic tool chaining if the tool is available in the servers connected
User: "Find charging stations near Silicon Valley and check their current status"

# Client automatically:
1. Uses Google Maps API to locate Silicon Valley
2. Searches for charging stations in the area
3. Checks station status through EV network API
4. Formats and presents results
```

### Resource Analysis
```python
# Automatic resource processing
User: "Analyze the contents of /path/to/document.pdf"

# Client automatically:
1. Identifies resource type
2. Extracts content
3. Processes through LLM
4. Provides intelligent summary
```

## ü§ù Contributing

We welcome contributions! See our [Contributing Guide](CONTRIBUTING.md) for details.

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üì¨ Contact & Support

- **Author**: Abiola Adeshina
- **Email**: abioladedayo1993@gmail.com
- **GitHub Issues**: [Report a bug](https://github.com/Abiorh001/mcp_connect/issues)

---

<p align="center">Built with ‚ù§Ô∏è by the MCPOmni Connect Team</p> 