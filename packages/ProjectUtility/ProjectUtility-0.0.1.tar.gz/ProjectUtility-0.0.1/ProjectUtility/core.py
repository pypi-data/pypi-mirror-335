# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['convert_palette_to_hex', 'create_group_color_mapping', 'norm_loading', 'quantileNormalize', 'norm_loading_TMT',
           'ires_norm', 'clean_id', 'hist_legend', 'parse_fasta_file', 'add_desc', 'get_scaled_df']

# %% ../nbs/00_core.ipynb 3
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.colors as mcolors
from matplotlib.patches import Patch
import numpy as np
import re

# %% ../nbs/00_core.ipynb 4
def convert_palette_to_hex(palette_name, n_colors):
    """
    Convert a named color palette to hex color codes.
    
    Parameters:
    -----------
    palette_name : str
        Name of the palette (e.g., 'tab10', 'Set1', 'husl', 'viridis')
    n_colors : int
        Number of colors to generate
        
    Returns:
    --------
    list
        List of hex color codes
    """

    
    try:
        # Try to get palette from seaborn
        palette = sns.color_palette(palette_name, n_colors)
        hex_colors = [mcolors.rgb2hex(color) for color in palette]
        return hex_colors
    except:
        try:
            # Try as a matplotlib colormap
            cmap = plt.cm.get_cmap(palette_name, n_colors)
            hex_colors = [mcolors.rgb2hex(cmap(i)) for i in range(n_colors)]
            return hex_colors
        except:
            # Fallback to default
            print(f"Palette '{palette_name}' not found, using default.")
            return sns.color_palette("husl", n_colors).as_hex()


# %% ../nbs/00_core.ipynb 5
def create_group_color_mapping(items, group_size=3, palette=None, palette_name=None, return_color_to_group=False):
    """
    Create a color mapping dictionary that assigns the same color to items in groups.
    
    Parameters:
    -----------
    items : list
        List of items to be mapped to colors
    group_size : int
        Number of items to assign to each color (default: 3)
    palette : list or None
        List of colors to use. If None, uses default colors in hex format.
    palette_name : str or None
        Name of a seaborn/matplotlib palette (e.g., 'tab10', 'Set1') to use.
        This is used if palette is None.
    return_color_to_group : bool
        If True, also returns a dictionary mapping colors to group names
        
    Returns:
    --------
    dict or tuple
        Dictionary mapping each item to its assigned color (hex format)
        If return_color_to_group is True, also returns a dict mapping colors to group names
    """
    # Calculate how many colors we need
    num_groups = (len(items) + group_size - 1) // group_size  # Ceiling division
    
    # Generate or use provided color palette in hex format
    if palette is None:
        if palette_name is not None:
            # Use the specified palette name
            colors = convert_palette_to_hex(palette_name, num_groups)
        else:
            # Default hex color palette
            default_colors = [
                '#FF5733', '#33FF57', '#3357FF', '#FF33A8', '#33FFF5', 
                '#FFD133', '#A833FF', '#FF8D33', '#33ACFF', '#FF3352'
            ]
            
            # If we need more colors, generate them
            if num_groups > len(default_colors):
                
                
                # Use seaborn to generate additional colors in hex
                additional_colors = sns.color_palette("husl", num_groups - len(default_colors)).as_hex()
                colors = default_colors + additional_colors
            else:
                colors = default_colors[:num_groups]
    else:
        # Convert any non-hex colors in provided palette to hex format
        
        colors = []
        for color in palette:
            if isinstance(color, str) and color.startswith('#'):
                colors.append(color)
            else:
                try:
                    colors.append(mcolors.to_hex(color))
                except:
                    colors.append('#888888')  # Default gray if conversion fails
        
        # If palette is too small, cycle it
        if len(colors) < num_groups:
            colors = colors * (num_groups // len(colors) + 1)
        
        colors = colors[:num_groups]
    
    # Create the mapping dictionary
    color_mapping = {}
    # If requested, also create a mapping from color to group name
    color_to_group = {}
    
    for i, item in enumerate(items):
        group_idx = i // group_size
        group_name = f"Group {group_idx + 1}"
        color_idx = min(group_idx, len(colors) - 1)  # Ensure we don't go out of bounds
        color = colors[color_idx]
        
        color_mapping[item] = color
        
        # Add to color_to_group dictionary if it doesn't exist yet
        if return_color_to_group and color not in color_to_group:
            color_to_group[color] = group_name
    
    if return_color_to_group:
        return color_mapping, color_to_group
    else:
        return color_mapping



# %% ../nbs/00_core.ipynb 8
def norm_loading(df):
    '''
    normalization loading for the columns of a dataframe
    the columns shuld be comparable (ie do not mix fractionated samples,
    for example cytosolic and extracellulars)
    '''
    medians = df.median(axis=0)
    print('medians',np.array(medians))
    target = np.mean(medians)
    print('target', target)
    norm_facs = target / medians
    print('norm_facs', np.array(norm_facs))
    data_norm = df.multiply(norm_facs, axis=1)
    return data_norm

def quantileNormalize(df_input, keep_na=True):
    df = df_input.copy()
    #compute rank
    dic = {}
    for col in df:
        dic.update({col : sorted(df[col])})
    sorted_df = pd.DataFrame(dic)
    rank = sorted_df.mean(axis = 1).tolist()
    #sort
    for col in df:
        t = np.searchsorted(np.sort(df[col]), df[col])
        norm = [rank[i] for i in t]
        if keep_na == True:
            norm = [np.nan if np.isnan(a) else b for a,b in zip(df[col],norm)]
        df[col] =  norm             
    return df

def norm_loading_TMT(df):
    #normalization of dataframe
    #to account for uneven loading
    #only for TMT datasets
    col_sum = df.sum(axis=0)
    #print(col_sum)
    target = np.mean(col_sum)
    #print(target)
    norm_facs = target / col_sum
    #print(norm_facs)
    data_norm = df.multiply(norm_facs, axis=1)
    return  data_norm

# %% ../nbs/00_core.ipynb 9
def ires_norm(df, exps_columns):
    '''
    implement IRES norm for TMT
    example
    irs_df = ires_norm(df.replace(0,np.nan).fillna(df.mean()),[tmt10, tmt6])
    remember to set nan again after norm
    irs_df[df.replace(0,np.nan).isna()]=np.nan
    '''
    
    # Ensure the DataFrame contains the required columns
    if not all(col in df for cols in exps_columns for col in cols):
        raise ValueError("DataFrame does not contain all the required columns")
    
    
    df_list = [df[exp_cols] for exp_cols in exps_columns]

    # Sum by row for each experiment and concatenate results
    df_sums = pd.concat([exp.sum(axis=1, skipna=True) for exp in df_list], axis=1)
    df_sums.columns = [f'exp_{n+1}' for n in range(len(exps_columns))]

    # Compute geometric mean of sums
    # Add a small constant for numerical stability
    df_sums["gmean"] = np.exp(np.nanmean(np.log(df_sums+1e-8), axis=1))  

    # Compute and apply scaling factors
    for n, _ in enumerate(exps_columns):
        scaling_col = f'exp_{n+1}_scaling'
        df_sums[scaling_col] = df_sums["gmean"] / df_sums[f'exp_{n+1}']
        df_list[n] = df_list[n].multiply(df_sums[scaling_col].values, axis=0)

    final_df = pd.concat(df_list, axis=1)


    
    final_df = norm_loading_TMT(final_df)

    return final_df

# %% ../nbs/00_core.ipynb 10
#get only the gene id from
#the new TryTripDB format
def clean_id(temp_id):
    temp_id = temp_id.split(':')[0]
    if temp_id.count('.')>2:
        temp_id = '.'.join(temp_id.split('.')[0:3])
    return temp_id

# %% ../nbs/00_core.ipynb 11
#format legend of hist plots 
#with lines instead of boxes
def hist_legend(ax, title = False):
    handles, labels = ax.get_legend_handles_labels()
    new_handles = [Line2D([], [], c=h.get_edgecolor()) for h in handles]
    ax.legend(handles=new_handles, labels=labels, 
    title=title,loc='center left', bbox_to_anchor=(1, 0.5))  

# %% ../nbs/00_core.ipynb 12
def parse_fasta_file(fasta_file):
    '''
    create a dictionary of protein id to gene product
    using fasta file from tritrypDB
    '''
    protein_dict = {}
    current_protein_id = None

    with open(fasta_file, 'r') as f:
        for line in f:
            if line.startswith('>'):
                protein_id = '.'.join(line.split('>')[1].split('.')[0:-3]).split(':')[0]
                gene_product_match = re.search(r'gene_product=([^|]+)', line)

                if  gene_product_match:
                    #protein_id = protein_id_match.group(1)
                    gene_product = gene_product_match.group(1)
                    protein_dict[protein_id] = gene_product.strip()
                    current_protein_id = protein_id
                else:
                    current_protein_id = None
    return protein_dict

def add_desc(data, prot_to_desc):
    desc = []
    for item in data.index.values:
        item_desc = []
        for prot in item.split(';'):
            clean_prot = prot.split(':')[0]
            item_desc.append(prot_to_desc.get(clean_prot,clean_prot))
        item_desc = ';'.join(item_desc)
        desc.append(item_desc)                        
    return desc

# %% ../nbs/00_core.ipynb 13
from sklearn.preprocessing import StandardScaler

def get_scaled_df(df):
    scaler = StandardScaler()
    tmp_df = np.log10(df).dropna().copy()
    tmp_df.index = [n .split(':') [0] for n in tmp_df.index.values]
    tmp_df = pd.DataFrame(scaler.fit_transform(tmp_df),
                          index=tmp_df.index,columns=tmp_df.columns)
    return tmp_df

