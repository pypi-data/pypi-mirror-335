{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7186371d-a854-4609-8158-8537db05c369",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "\n",
    "> In this assignment, you will\n",
    ">    1) explore Wikipedia text data\n",
    ">    2) build language models\n",
    "\n",
    "> Download the preprocessed data, enwiki-train.json and enwiki-test.json. In the data file, each line contains a Wikipedia page with attributes, title, label, and text. There are 1000 records in the train file and 100 records in test file with ten categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cc7cb5-dd64-4886-8cd5-24f147288941",
   "metadata": {},
   "source": [
    "## Task1 - Data exploring and preprocessing\n",
    "\n",
    "> 1) Print out how many documents are in each class  (for both train and test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ba34ae-48ae-438a-b3dd-c9d4cb3ee416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes to here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a2d5c-b719-41ec-8f14-04e092517eb9",
   "metadata": {},
   "source": [
    "> 2) Print out the average number of sentences in each class.\n",
    ">    You may need to use sentence tokenization of NLTK.\n",
    ">    (for both train and test dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e85dc7-d50b-406a-9550-b2063f236ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes to here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ef409-65a5-4d07-9b69-c5986569970a",
   "metadata": {},
   "source": [
    "> 3) Print out the average number of tokens in each class\n",
    ">    (for both train and test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4d7628e-762c-49fe-804a-796fa0265af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes to here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d999a66-977c-469b-939c-c3934210972e",
   "metadata": {},
   "source": [
    "> 4) For each sentence in the document, remove punctuations and other special characters so that each sentence only contains English words and numbers. To make your life easier, you can make all words as lower cases. For each class, print out the first article's name and the processed first 40 words. (for both train and test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "819a28ef-0821-4ace-be70-fb9b249d355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes to here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6c7ea9-18fa-43f1-bded-625c09a947b1",
   "metadata": {},
   "source": [
    "## Task2 - Build language models\n",
    "\n",
    "> 1) Based on the training dataset, build bigram language models using Add-one smoothing technique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e979b1-235f-4663-8acc-00257735e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes to here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6edc5-78c5-4de0-8855-2a455d625c97",
   "metadata": {},
   "source": [
    "> 2) Report the perplexity of your trained models on the testing dataset and explain your findings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3acda9a7-606c-4fa6-918a-9ebe7745ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes to here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd75b35-134d-4629-ac87-ed84fcc9d8e4",
   "metadata": {},
   "source": [
    "> 3) Use your built model to generate five sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea6e1244-2b15-4845-a83b-5708797569b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes to here\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
