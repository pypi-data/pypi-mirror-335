{
    "coref": {
        "Accuracy": [
            [2719, 2720],
            [2721, 2722],
            [2741, 2742],
            [2779, 2780],
            [3172, 3173]
        ],
        "Matched": [],
        "Mismatched": [],
        "MultiNLI": [
            [93, 94],
            [1093, 1094],
            [2311, 2312],
            [2785, 2786],
            [2179, 2180],
            [2666, 2667]
        ],
        "Natural_Language_Inference": [
            [140, 143],
            [144, 146],
            [197, 200],
            [217, 218],
            [259, 260],
            [352, 355],
            [375, 376],
            [516, 519],
            [2086, 2089],
            [3107, 3108]
        ],
        "Quora_Question_Pairs": [
            [95, 96],
            [1095, 1096],
            [2365, 2366],
            [2697, 2699],
            [2793, 2794],
            [2184, 2185],
            [2367, 2368]
        ],
        "SNLI": [
            [91, 92],
            [1091, 1092],
            [2225, 2226],
            [2567, 2568],
            [2839, 2840],
            [201, 202],
            [2167, 2168],
            [2232, 2233],
            [2337, 2338],
            [2763, 2764]
        ],
        "__Test_Accuracy": [],
        "aESIM": [
            [2, 7],
            [22, 28],
            [29, 30],
            [60, 63],
            [99, 100],
            [1086, 1087],
            [1102, 1104],
            [1166, 1167],
            [1199, 1204],
            [1502, 1504],
            [1511, 1516],
            [1518, 1520],
            [1531, 1532],
            [1559, 1560],
            [1584, 1585],
            [2412, 2414],
            [2547, 2548],
            [2614, 2615],
            [2628, 2629],
            [2664, 2665],
            [2757, 2759],
            [2800, 2801],
            [2979, 2981],
            [2985, 2986],
            [3024, 3026],
            [3059, 3061],
            [3073, 3075],
            [3105, 3106],
            [3124, 3126],
            [3135, 3137]
        ]
    },
    "doc_id": "007ff2ca5f297b04636699ce4d01ca6d6f21dc77",
    "method_subrelations": {
        "aESIM": [
            [[0, 5], "aESIM"]
        ]
    },
    "n_ary_relations": [
        {
            "Material": "MultiNLI",
            "Method": "aESIM",
            "Metric": "Matched",
            "Task": "Natural_Language_Inference",
            "score": "73.9 "
        },
        {
            "Material": "MultiNLI",
            "Method": "aESIM",
            "Metric": "Mismatched",
            "Task": "Natural_Language_Inference",
            "score": "73.9"
        },
        {
            "Material": "Quora_Question_Pairs",
            "Method": "aESIM",
            "Metric": "Accuracy",
            "Task": "Natural_Language_Inference",
            "score": "88.01"
        },
        {
            "Material": "SNLI",
            "Method": "aESIM",
            "Metric": "__Test_Accuracy",
            "Task": "Natural_Language_Inference",
            "score": "88.1"
        }
    ],
    "ner": [
        [2, 7, "Method"],
        [7, 9, "Method"],
        [14, 17, "Task"],
        [22, 28, "Method"],
        [29, 30, "Method"],
        [32, 34, "Method"],
        [35, 41, "Method"],
        [44, 53, "Method"],
        [55, 56, "Method"],
        [60, 63, "Method"],
        [76, 79, "Task"],
        [91, 92, "Material"],
        [93, 94, "Material"],
        [95, 96, "Material"],
        [99, 100, "Method"],
        [105, 107, "Method"],
        [140, 143, "Task"],
        [144, 146, "Task"],
        [153, 159, "Task"],
        [197, 200, "Task"],
        [217, 218, "Task"],
        [223, 225, "Task"],
        [259, 260, "Task"],
        [268, 272, "Method"],
        [273, 278, "Method"],
        [279, 283, "Method"],
        [314, 315, "Method"],
        [317, 319, "Task"],
        [322, 332, "Method"],
        [346, 348, "Task"],
        [349, 351, "Task"],
        [352, 355, "Task"],
        [369, 374, "Method"],
        [375, 376, "Task"],
        [380, 383, "Method"],
        [384, 389, "Method"],
        [406, 409, "Method"],
        [451, 457, "Method"],
        [463, 471, "Method"],
        [475, 480, "Method"],
        [482, 485, "Method"],
        [516, 519, "Task"],
        [522, 525, "Method"],
        [526, 529, "Method"],
        [530, 533, "Method"],
        [534, 538, "Method"],
        [539, 543, "Method"],
        [544, 547, "Method"],
        [554, 557, "Method"],
        [558, 560, "Method"],
        [571, 581, "Method"],
        [591, 594, "Method"],
        [598, 601, "Method"],
        [615, 618, "Method"],
        [620, 621, "Method"],
        [622, 624, "Method"],
        [633, 635, "Task"],
        [649, 651, "Method"],
        [657, 662, "Method"],
        [676, 678, "Method"],
        [687, 690, "Method"],
        [724, 727, "Method"],
        [728, 733, "Method"],
        [769, 772, "Task"],
        [775, 777, "Method"],
        [778, 781, "Task"],
        [782, 783, "Task"],
        [791, 795, "Method"],
        [796, 798, "Method"],
        [819, 828, "Method"],
        [832, 834, "Method"],
        [859, 864, "Method"],
        [866, 867, "Method"],
        [868, 872, "Method"],
        [877, 880, "Method"],
        [882, 884, "Method"],
        [888, 891, "Method"],
        [893, 894, "Method"],
        [914, 918, "Method"],
        [919, 921, "Task"],
        [942, 946, "Method"],
        [974, 978, "Method"],
        [987, 990, "Method"],
        [1011, 1013, "Task"],
        [1033, 1035, "Method"],
        [1042, 1044, "Method"],
        [1046, 1050, "Method"],
        [1054, 1058, "Method"],
        [1070, 1075, "Method"],
        [1076, 1079, "Method"],
        [1084, 1085, "Method"],
        [1086, 1087, "Method"],
        [1091, 1092, "Material"],
        [1093, 1094, "Material"],
        [1095, 1096, "Material"],
        [1102, 1104, "Method"],
        [1109, 1110, "Method"],
        [1128, 1131, "Method"],
        [1138, 1140, "Task"],
        [1142, 1144, "Task"],
        [1145, 1147, "Task"],
        [1164, 1165, "Method"],
        [1166, 1167, "Method"],
        [1199, 1204, "Method"],
        [1233, 1235, "Method"],
        [1235, 1239, "Method"],
        [1240, 1241, "Method"],
        [1249, 1252, "Method"],
        [1253, 1257, "Method"],
        [1258, 1261, "Method"],
        [1262, 1264, "Method"],
        [1267, 1270, "Method"],
        [1271, 1272, "Method"],
        [1274, 1278, "Method"],
        [1298, 1300, "Method"],
        [1328, 1329, "Method"],
        [1331, 1334, "Method"],
        [1387, 1389, "Task"],
        [1391, 1395, "Method"],
        [1406, 1408, "Task"],
        [1411, 1412, "Method"],
        [1419, 1420, "Method"],
        [1424, 1428, "Method"],
        [1438, 1439, "Method"],
        [1441, 1447, "Method"],
        [1466, 1468, "Method"],
        [1476, 1478, "Method"],
        [1483, 1485, "Method"],
        [1487, 1490, "Method"],
        [1496, 1499, "Method"],
        [1502, 1504, "Method"],
        [1511, 1516, "Method"],
        [1518, 1520, "Method"],
        [1522, 1523, "Method"],
        [1526, 1527, "Method"],
        [1531, 1532, "Method"],
        [1539, 1541, "Method"],
        [1542, 1546, "Method"],
        [1547, 1549, "Method"],
        [1550, 1552, "Method"],
        [1557, 1558, "Method"],
        [1559, 1560, "Method"],
        [1566, 1570, "Method"],
        [1571, 1572, "Method"],
        [1573, 1574, "Method"],
        [1576, 1577, "Method"],
        [1579, 1583, "Method"],
        [1584, 1585, "Method"],
        [1604, 1605, "Method"],
        [1610, 1614, "Method"],
        [1630, 1633, "Method"],
        [1662, 1664, "Method"],
        [1672, 1676, "Method"],
        [1680, 1684, "Method"],
        [1687, 1691, "Method"],
        [1695, 1698, "Method"],
        [1700, 1703, "Method"],
        [1721, 1724, "Method"],
        [1730, 1732, "Method"],
        [1737, 1741, "Method"],
        [1742, 1745, "Method"],
        [1761, 1763, "Method"],
        [1797, 1799, "Method"],
        [1813, 1817, "Method"],
        [1831, 1833, "Method"],
        [1876, 1880, "Method"],
        [1882, 1886, "Method"],
        [1904, 1906, "Method"],
        [1971, 1974, "Method"],
        [2044, 2051, "Method"],
        [2053, 2056, "Method"],
        [2072, 2074, "Method"],
        [2078, 2082, "Method"],
        [2086, 2089, "Task"],
        [2093, 2096, "Method"],
        [2112, 2115, "Method"],
        [2122, 2126, "Method"],
        [2127, 2130, "Task"],
        [2202, 2205, "Method"],
        [2208, 2210, "Metric"],
        [2225, 2226, "Material"],
        [2311, 2312, "Material"],
        [2359, 2364, "Task"],
        [2365, 2366, "Material"],
        [2412, 2414, "Method"],
        [2422, 2424, "Method"],
        [2425, 2426, "Task"],
        [2442, 2444, "Metric"],
        [2463, 2466, "Method"],
        [2467, 2469, "Method"],
        [2479, 2482, "Method"],
        [2487, 2489, "Metric"],
        [2490, 2492, "Metric"],
        [2515, 2524, "Task"],
        [2528, 2530, "Method"],
        [2547, 2548, "Method"],
        [2549, 2550, "Method"],
        [2567, 2568, "Material"],
        [2584, 2587, "Method"],
        [2594, 2599, "Method"],
        [2605, 2609, "Method"],
        [2611, 2612, "Method"],
        [2614, 2615, "Method"],
        [2626, 2627, "Method"],
        [2628, 2629, "Method"],
        [2634, 2635, "Method"],
        [2655, 2656, "Method"],
        [2657, 2660, "Method"],
        [2661, 2662, "Method"],
        [2664, 2665, "Method"],
        [2697, 2699, "Material"],
        [2710, 2711, "Method"],
        [2712, 2714, "Method"],
        [2719, 2720, "Metric"],
        [2721, 2722, "Metric"],
        [2732, 2734, "Metric"],
        [2741, 2742, "Metric"],
        [2757, 2759, "Method"],
        [2771, 2773, "Method"],
        [2779, 2780, "Metric"],
        [2785, 2786, "Material"],
        [2793, 2794, "Material"],
        [2800, 2801, "Method"],
        [2812, 2814, "Method"],
        [2817, 2819, "Task"],
        [2839, 2840, "Material"],
        [2964, 2968, "Method"],
        [2969, 2971, "Method"],
        [2974, 2978, "Method"],
        [2979, 2981, "Method"],
        [2983, 2984, "Method"],
        [2985, 2986, "Method"],
        [3024, 3026, "Method"],
        [3031, 3033, "Method"],
        [3059, 3061, "Method"],
        [3067, 3069, "Method"],
        [3073, 3075, "Method"],
        [3103, 3104, "Method"],
        [3105, 3106, "Method"],
        [3107, 3108, "Task"],
        [3112, 3116, "Method"],
        [3124, 3126, "Method"],
        [3135, 3137, "Method"],
        [3141, 3143, "Method"],
        [3152, 3154, "Method"],
        [201, 202, "Material"],
        [1460, 1461, "Method"],
        [2101, 2104, "Task"],
        [2167, 2168, "Material"],
        [2179, 2180, "Material"],
        [2184, 2185, "Material"],
        [2232, 2233, "Material"],
        [2337, 2338, "Material"],
        [2367, 2368, "Material"],
        [2666, 2667, "Material"],
        [2692, 2693, "Method"],
        [2694, 2696, "Method"],
        [2763, 2764, "Material"],
        [3172, 3173, "Metric"
        ]
    ],
    "sections": [
        [0, 137],
        [137, 1197],
        [1197, 1231],
        [1231, 1500],
        [1500, 2146],
        [2146, 2150],
        [2150, 2393],
        [2393, 2538],
        [2538, 2815],
        [2815, 3090],
        [3090, 3174],
        [3174, 3215],
        [3215, 3218
        ]
    ],
    "sentences": [
        [0, 7],
        [7, 18],
        [18, 57],
        [57, 86],
        [86, 108],
        [108, 118],
        [118, 121],
        [121, 132],
        [132, 137],
        [137, 140],
        [140, 160],
        [160, 189],
        [189, 210],
        [210, 226],
        [226, 255],
        [255, 279],
        [279, 320],
        [320, 358],
        [358, 390],
        [390, 406],
        [406, 459],
        [459, 506],
        [506, 548],
        [548, 565],
        [565, 585],
        [585, 619],
        [619, 636],
        [636, 657],
        [657, 722],
        [722, 759],
        [759, 785],
        [785, 812],
        [812, 844],
        [844, 892],
        [892, 919],
        [919, 930],
        [930, 947],
        [947, 972],
        [972, 994],
        [994, 1026],
        [1026, 1067],
        [1067, 1088],
        [1088, 1122],
        [1122, 1151],
        [1151, 1158],
        [1158, 1171],
        [1171, 1189],
        [1189, 1197],
        [1197, 1204],
        [1204, 1219],
        [1219, 1231],
        [1231, 1235],
        [1235, 1265],
        [1265, 1326],
        [1326, 1340],
        [1340, 1350],
        [1350, 1372],
        [1372, 1383],
        [1383, 1409],
        [1409, 1448],
        [1448, 1479],
        [1479, 1500],
        [1500, 1504],
        [1504, 1528],
        [1528, 1553],
        [1553, 1586],
        [1586, 1642],
        [1642, 1692],
        [1692, 1710],
        [1710, 1742],
        [1742, 1745],
        [1745, 1761],
        [1761, 1791],
        [1791, 1804],
        [1804, 1876],
        [1876, 1907],
        [1907, 1924],
        [1924, 1942],
        [1942, 1965],
        [1965, 1986],
        [1986, 2023],
        [2023, 2032],
        [2032, 2057],
        [2057, 2090],
        [2090, 2146],
        [2146, 2150],
        [2150, 2153],
        [2153, 2161],
        [2161, 2189],
        [2189, 2225],
        [2225, 2226],
        [2226, 2233],
        [2233, 2258],
        [2258, 2277],
        [2277, 2292],
        [2292, 2311],
        [2311, 2312],
        [2312, 2331],
        [2331, 2365],
        [2365, 2366],
        [2366, 2376],
        [2376, 2393],
        [2393, 2396],
        [2396, 2407],
        [2407, 2419],
        [2419, 2427],
        [2427, 2440],
        [2440, 2456],
        [2456, 2472],
        [2472, 2490],
        [2490, 2499],
        [2499, 2515],
        [2515, 2531],
        [2531, 2538],
        [2538, 2542],
        [2542, 2569],
        [2569, 2622],
        [2622, 2648],
        [2648, 2685],
        [2685, 2718],
        [2718, 2747],
        [2747, 2774],
        [2774, 2787],
        [2787, 2795],
        [2795, 2815],
        [2815, 2819],
        [2819, 2884],
        [2884, 2901],
        [2901, 2905],
        [2905, 2916],
        [2916, 2948],
        [2948, 2987],
        [2987, 3004],
        [3004, 3019],
        [3019, 3045],
        [3045, 3070],
        [3070, 3090],
        [3090, 3093],
        [3093, 3109],
        [3109, 3121],
        [3121, 3131],
        [3131, 3144],
        [3144, 3174],
        [3174, 3177],
        [3177, 3191],
        [3191, 3195],
        [3195, 3209],
        [3209, 3215],
        [3215, 3218
        ]
    ],
    "words": [
        "document",
        ":",
        "Attention",
        "Boosted",
        "Sequential",
        "Inference",
        "Model",
        "Attention",
        "mechanism",
        "has",
        "been",
        "proven",
        "effective",
        "on",
        "natural",
        "language",
        "processing",
        ".",
        "This",
        "paper",
        "proposes",
        "an",
        "attention",
        "boosted",
        "natural",
        "language",
        "inference",
        "model",
        "named",
        "aESIM",
        "by",
        "adding",
        "word",
        "attention",
        "and",
        "adaptive",
        "direction",
        "-",
        "oriented",
        "attention",
        "mechanisms",
        "to",
        "the",
        "traditional",
        "Bi",
        "-",
        "LSTM",
        "layer",
        "of",
        "natural",
        "language",
        "inference",
        "models",
        ",",
        "e.g.",
        "ESIM",
        ".",
        "This",
        "makes",
        "the",
        "inference",
        "model",
        "aESIM",
        "has",
        "the",
        "ability",
        "to",
        "effectively",
        "learn",
        "the",
        "representation",
        "of",
        "words",
        "and",
        "model",
        "the",
        "local",
        "subsentential",
        "inference",
        "between",
        "pairs",
        "of",
        "premise",
        "and",
        "hypothesis",
        ".",
        "The",
        "empirical",
        "studies",
        "on",
        "the",
        "SNLI",
        ",",
        "MultiNLI",
        "and",
        "Quora",
        "benchmarks",
        "manifest",
        "that",
        "aESIM",
        "is",
        "superior",
        "to",
        "the",
        "original",
        "ESIM",
        "model",
        ".",
        "acmlicensed",
        "[",
        "DAPA\u201919",
        "]",
        "DAPA2019WSDMWorkshoponDeepmatchinginPracticalApplicationsFebruary15th",
        ",",
        "2019Melbourne",
        ",",
        "Australia",
        "2019",
        "2019",
        "printacmref",
        "=",
        "false",
        "1234",
        "-",
        "5678",
        "-",
        "9012",
        "1234",
        "-",
        "5678",
        "-",
        "9012",
        "1234",
        "-",
        "5678",
        "-",
        "9012",
        "section",
        ":",
        "Introduction",
        "Natural",
        "language",
        "inference",
        "(",
        "NLI",
        ")",
        "is",
        "an",
        "important",
        "and",
        "significant",
        "task",
        "in",
        "natural",
        "language",
        "processing",
        "(",
        "NLP",
        ")",
        ".",
        "It",
        "concerns",
        "whether",
        "a",
        "hypothesis",
        "can",
        "be",
        "inferred",
        "from",
        "a",
        "premise",
        ",",
        "requiring",
        "understanding",
        "of",
        "the",
        "semantic",
        "similarity",
        "between",
        "the",
        "hypothesis",
        "and",
        "the",
        "premise",
        "to",
        "discriminate",
        "their",
        "relation",
        ".",
        "Table",
        "[",
        "reference",
        "]",
        "shows",
        "several",
        "samples",
        "of",
        "natural",
        "language",
        "inference",
        "from",
        "SNLI",
        "(",
        "Stanford",
        "Natural",
        "Language",
        "Inference",
        ")",
        "corpus",
        ".",
        "In",
        "the",
        "literature",
        ",",
        "the",
        "task",
        "of",
        "NLI",
        "is",
        "usually",
        "viewed",
        "as",
        "a",
        "relation",
        "classification",
        ".",
        "It",
        "learns",
        "the",
        "relation",
        "between",
        "a",
        "premise",
        "and",
        "a",
        "hypothesis",
        "in",
        "a",
        "large",
        "training",
        "set",
        ",",
        "then",
        "predicts",
        "the",
        "relation",
        "between",
        "a",
        "new",
        "pair",
        "of",
        "premise",
        "and",
        "hypothesis",
        ".",
        "The",
        "existing",
        "methods",
        "of",
        "NLI",
        "can",
        "be",
        "roughly",
        "partitioned",
        "into",
        "two",
        "categories",
        ":",
        "feature",
        "-",
        "based",
        "models",
        "and",
        "neural",
        "network",
        "-",
        "based",
        "models",
        ".",
        "Feature",
        "-",
        "based",
        "models",
        "represent",
        "a",
        "premise",
        "and",
        "a",
        "hypothesis",
        "by",
        "their",
        "unlexicalized",
        "and",
        "lexicalized",
        "features",
        ",",
        "such",
        "as",
        "-",
        "gram",
        "length",
        "and",
        "the",
        "real",
        "-",
        "valued",
        "feature",
        "of",
        "length",
        "difference",
        ",",
        "then",
        "train",
        "a",
        "classifier",
        "to",
        "perform",
        "relation",
        "classification",
        ".",
        "Recently",
        ",",
        "end",
        "-",
        "to",
        "-",
        "end",
        "neural",
        "network",
        "-",
        "based",
        "models",
        "have",
        "drawn",
        "worldwide",
        "attention",
        "since",
        "they",
        "have",
        "demonstrated",
        "excellent",
        "performance",
        "on",
        "quite",
        "a",
        "few",
        "NLP",
        "tasks",
        "including",
        "machine",
        "translation",
        ",",
        "natural",
        "language",
        "inference",
        ",",
        "etc",
        ".",
        "On",
        "the",
        "basis",
        "of",
        "their",
        "model",
        "structures",
        ",",
        "we",
        "can",
        "divide",
        "neural",
        "network",
        "-",
        "based",
        "models",
        "for",
        "NLI",
        "into",
        "two",
        "classes",
        ",",
        "sentence",
        "encoding",
        "models",
        "and",
        "sentence",
        "interaction",
        "-",
        "aggregation",
        "models",
        ".",
        "The",
        "architectures",
        "of",
        "the",
        "two",
        "types",
        "of",
        "models",
        "are",
        "shown",
        "in",
        "Figure",
        "[",
        "reference",
        "]",
        ".",
        "Sentence",
        "encoding",
        "models",
        "(",
        "their",
        "main",
        "architecture",
        "is",
        "shown",
        "in",
        "Figure",
        "[",
        "reference",
        "]",
        ".a",
        ")",
        "independently",
        "encode",
        "a",
        "pair",
        "of",
        "sentences",
        ",",
        "a",
        "premise",
        "and",
        "a",
        "hypothesis",
        "using",
        "pre",
        "-",
        "trained",
        "word",
        "embedding",
        "vectors",
        ",",
        "then",
        "learn",
        "semantic",
        "relation",
        "between",
        "two",
        "sentences",
        "with",
        "a",
        "multi",
        "-",
        "layer",
        "perceptron",
        "(",
        "MLP",
        ")",
        ".",
        "In",
        "these",
        "models",
        ",",
        "LSTM",
        "(",
        "Long",
        "Short",
        "-",
        "Term",
        "Memory",
        "networks",
        ")",
        ",",
        "its",
        "variants",
        "GRU",
        "(",
        "Gated",
        "Recurrent",
        "Units",
        ")",
        "and",
        "Bi",
        "-",
        "LSTM",
        ",",
        "are",
        "usually",
        "utilized",
        "to",
        "encode",
        "the",
        "sentences",
        "since",
        "they",
        "were",
        "capable",
        "of",
        "learning",
        "long",
        "-",
        "term",
        "dependencies",
        "inside",
        "sentences",
        ".",
        "For",
        "example",
        ",",
        "Conneau",
        "et",
        "al",
        ".",
        "proposed",
        "a",
        "generic",
        "NLI",
        "training",
        "scheme",
        "and",
        "compared",
        "several",
        "sentence",
        "encoding",
        "architectures",
        ":",
        "LSTM",
        "or",
        "GRU",
        ",",
        "Bi",
        "-",
        "LSTM",
        "with",
        "mean",
        "/",
        "max",
        "pooling",
        ",",
        "self",
        "-",
        "attention",
        "network",
        "and",
        "hierarchical",
        "convolutional",
        "networks",
        ".",
        "The",
        "experimental",
        "results",
        "demonstrated",
        "that",
        "the",
        "Bi",
        "-",
        "LSTM",
        "with",
        "max",
        "pooling",
        "achieved",
        "the",
        "best",
        "performance",
        ".",
        "Talman",
        "et",
        "al",
        ".",
        "designed",
        "a",
        "hierarchical",
        "Bi",
        "-",
        "LSTM",
        "max",
        "pooling",
        "(",
        "HBMP",
        ")",
        "model",
        "to",
        "encode",
        "sentences",
        ".",
        "This",
        "model",
        "applied",
        "parameters",
        "of",
        "one",
        "Bi",
        "-",
        "LSTM",
        "to",
        "initialize",
        "the",
        "next",
        "Bi",
        "-",
        "LSTM",
        "to",
        "convey",
        "information",
        ",",
        "which",
        "shown",
        "better",
        "results",
        "than",
        "the",
        "model",
        "with",
        "a",
        "single",
        "Bi",
        "-",
        "LSTM",
        ".",
        "Besides",
        "LSTM",
        ",",
        "attention",
        "mechanisms",
        "could",
        "also",
        "be",
        "used",
        "to",
        "boost",
        "the",
        "effectiveness",
        "of",
        "sentence",
        "encoding",
        ".",
        "The",
        "model",
        "developed",
        "by",
        "Ghaeini",
        "et",
        "al",
        ".",
        "added",
        "self",
        "-",
        "attention",
        "to",
        "LSTM",
        "model",
        ",",
        "and",
        "achieved",
        "better",
        "performance",
        ".",
        "Sentence",
        "interaction",
        "-",
        "aggregation",
        "models",
        "(",
        "their",
        "main",
        "architecture",
        "is",
        "shown",
        "in",
        "Figure",
        "[",
        "reference",
        "]",
        ".b",
        ")",
        "learn",
        "vector",
        "representations",
        "of",
        "pairs",
        "of",
        "sentences",
        "in",
        "the",
        "way",
        "similar",
        "to",
        "sentence",
        "encoding",
        "models",
        "and",
        "calculate",
        "pairwise",
        "word",
        "interaction",
        "matrix",
        "between",
        "two",
        "sentences",
        "using",
        "the",
        "newly",
        "updated",
        "word",
        "vectors",
        ",",
        "and",
        "then",
        "the",
        "matching",
        "results",
        "are",
        "aggregated",
        "into",
        "a",
        "vector",
        "to",
        "make",
        "the",
        "final",
        "decision",
        ".",
        "Compared",
        "with",
        "sentence",
        "encoding",
        "model",
        ",",
        "sentence",
        "interaction",
        "-",
        "aggregation",
        "models",
        "aggregate",
        "word",
        "similarities",
        "between",
        "a",
        "pair",
        "of",
        "sentences",
        ",",
        "are",
        "capable",
        "of",
        "capturing",
        "the",
        "relevant",
        "information",
        "between",
        "two",
        "sentences",
        ",",
        "a",
        "premise",
        "and",
        "a",
        "hypothesis",
        ".",
        "Bahdanau",
        "et",
        "al",
        ".",
        "translated",
        "and",
        "aligned",
        "text",
        "simultaneously",
        "in",
        "machine",
        "translation",
        "task",
        ",",
        "innovatively",
        "introducing",
        "attention",
        "mechanism",
        "to",
        "natural",
        "language",
        "process",
        "(",
        "NLP",
        ")",
        ".",
        "He",
        "et",
        "al",
        ".",
        "designed",
        "a",
        "pairwise",
        "word",
        "interaction",
        "model",
        "(",
        "PWIM",
        ")",
        ",",
        "which",
        "made",
        "full",
        "use",
        "of",
        "word",
        "-",
        "level",
        "fine",
        "-",
        "grained",
        "information",
        ".",
        "Wang",
        "et",
        "al",
        ".",
        "put",
        "forward",
        "a",
        "bilateral",
        "multi",
        "-",
        "perspective",
        "matching",
        "(",
        "BiMPM",
        ")",
        "model",
        ",",
        "focusing",
        "on",
        "various",
        "matching",
        "strategies",
        "that",
        "could",
        "be",
        "seen",
        "as",
        "different",
        "types",
        "of",
        "attention",
        ".",
        "The",
        "empirical",
        "studies",
        "of",
        "Lan",
        "et",
        "al",
        ".",
        "and",
        "Chen",
        "et",
        "al",
        ".",
        "concluded",
        "that",
        "sentence",
        "interation",
        "-",
        "aggregation",
        "models",
        ",",
        "especially",
        "ESIM",
        "(",
        "Enhanced",
        "Sequential",
        "Inference",
        "Model",
        ")",
        ",",
        "a",
        "carefully",
        "designed",
        "sequential",
        "inference",
        "model",
        "based",
        "on",
        "chain",
        "LSTMs",
        ",",
        "outperformed",
        "all",
        "previous",
        "sentence",
        "encoding",
        "models",
        ".",
        "Although",
        "ESIM",
        "has",
        "achieved",
        "excellent",
        "achievements",
        ",",
        "this",
        "model",
        "does",
        "n\u2019t",
        "consider",
        "the",
        "attention",
        "along",
        "the",
        "words",
        "in",
        "a",
        "sentence",
        "in",
        "its",
        "Bi",
        "-",
        "LSTM",
        "layer",
        ".",
        "Word",
        "attention",
        "can",
        "characterize",
        "the",
        "different",
        "contribution",
        "of",
        "each",
        "word",
        ".",
        "Therefore",
        ",",
        "it",
        "will",
        "be",
        "beneficial",
        "to",
        "put",
        "word",
        "attention",
        "into",
        "the",
        "Bi",
        "-",
        "LTSM",
        "layer",
        ".",
        "Moreover",
        ",",
        "the",
        "orientation",
        "of",
        "the",
        "words",
        "represents",
        "the",
        "direction",
        "of",
        "the",
        "information",
        "flow",
        ",",
        "either",
        "forward",
        "or",
        "backward",
        ",",
        "should",
        "not",
        "be",
        "ignored",
        ".",
        "In",
        "traditional",
        "Bi",
        "-",
        "LSTM",
        "model",
        ",",
        "the",
        "forward",
        "and",
        "the",
        "backward",
        "vectors",
        "learnt",
        "by",
        "Bi",
        "-",
        "LSTM",
        "are",
        "simply",
        "jointed",
        ".",
        "It",
        "\u2019s",
        "necessary",
        "to",
        "consider",
        "whether",
        "each",
        "orientation",
        "(",
        "forward",
        "or",
        "backward",
        ")",
        "has",
        "different",
        "importance",
        "on",
        "word",
        "encoding",
        ",",
        "thus",
        "adaptively",
        "joint",
        "the",
        "two",
        "orientation",
        "vectors",
        "together",
        "with",
        "different",
        "weights",
        ".",
        "Therefore",
        ",",
        "in",
        "this",
        "study",
        ",",
        "using",
        "ESIM",
        "model",
        "as",
        "the",
        "baseline",
        ",",
        "we",
        "add",
        "an",
        "attention",
        "layer",
        "behind",
        "each",
        "Bi",
        "-",
        "LSTM",
        "layer",
        ",",
        "then",
        "use",
        "an",
        "adaptive",
        "orientation",
        "embedding",
        "layer",
        "to",
        "jointly",
        "represent",
        "the",
        "forward",
        "and",
        "backward",
        "vectors",
        ".",
        "We",
        "name",
        "this",
        "attention",
        "boosted",
        "Bi",
        "-",
        "LSTM",
        "as",
        "Bi",
        "-",
        "aLSTM",
        ",",
        "and",
        "denote",
        "the",
        "modified",
        "ESIM",
        "as",
        "aESIM",
        ".",
        "Experimental",
        "results",
        "on",
        "SNLI",
        ",",
        "MultiNLI",
        "and",
        "Quora",
        "benchmarks",
        "have",
        "demonstrated",
        "better",
        "performance",
        "of",
        "aESIM",
        "model",
        "than",
        "that",
        "of",
        "the",
        "baseline",
        "ESIM",
        "and",
        "the",
        "other",
        "state",
        "-",
        "of",
        "-",
        "the",
        "-",
        "art",
        "models",
        ".",
        "We",
        "believe",
        "that",
        "the",
        "architecture",
        "of",
        "Bi",
        "-",
        "aLSTM",
        "has",
        "potentially",
        "to",
        "be",
        "used",
        "in",
        "other",
        "NLP",
        "tasks",
        "such",
        "as",
        "text",
        "classification",
        ",",
        "machine",
        "translation",
        "and",
        "so",
        "on",
        ".",
        "This",
        "paper",
        "is",
        "organized",
        "as",
        "follows",
        ".",
        "We",
        "introduce",
        "the",
        "general",
        "frameworks",
        "of",
        "ESIM",
        "and",
        "aESIM",
        "in",
        "Section",
        "2",
        ".",
        "We",
        "describe",
        "the",
        "datasets",
        "and",
        "the",
        "experiment",
        "settings",
        ",",
        "and",
        "analyze",
        "our",
        "experimental",
        "results",
        "in",
        "Section",
        "3",
        ".",
        "We",
        "then",
        "draw",
        "conclusions",
        "in",
        "Section",
        "4",
        ".",
        "section",
        ":",
        "Attention",
        "Boosted",
        "Sequential",
        "Inference",
        "Model",
        "Supposed",
        "that",
        "we",
        "have",
        "two",
        "sentences",
        "and",
        ",",
        "where",
        "represents",
        "premise",
        "and",
        "represents",
        "hypothesis",
        ".",
        "The",
        "goal",
        "is",
        "to",
        "predict",
        "the",
        "label",
        "meaning",
        "for",
        "their",
        "relation",
        ".",
        "subsection",
        ":",
        "ESIM",
        "model",
        "Enhanced",
        "Sequential",
        "Inference",
        "Model",
        "(",
        "ESIM",
        ")",
        "is",
        "composed",
        "of",
        "four",
        "main",
        "components",
        ":",
        "input",
        "encoding",
        "layer",
        ",",
        "local",
        "inference",
        "modeling",
        "layer",
        ",",
        "inference",
        "composition",
        "layer",
        "and",
        "classification",
        "layer",
        ".",
        "In",
        "the",
        "input",
        "encoding",
        "layer",
        ",",
        "ESIM",
        "first",
        "uses",
        "Bi",
        "-",
        "LSTM",
        "layer",
        "to",
        "encode",
        "input",
        "sentence",
        "pairs",
        "(",
        "Equations",
        "1",
        "-",
        "2",
        ")",
        ",",
        "which",
        "can",
        "be",
        "initialized",
        "using",
        "pre",
        "-",
        "trained",
        "word",
        "embeddings",
        "(",
        "e.g.",
        "Glove",
        "840B",
        "vectors",
        ")",
        ",",
        "where",
        "is",
        "the",
        "word",
        "embedding",
        "vector",
        "of",
        "the",
        "-",
        "th",
        "word",
        "in",
        ",",
        "is",
        "that",
        "of",
        "word",
        "in",
        ".",
        "Secondly",
        ",",
        "ESIM",
        "implements",
        "the",
        "local",
        "inference",
        "layer",
        "for",
        "enhancing",
        "the",
        "sentence",
        "information",
        ".",
        "First",
        "it",
        "calculates",
        "a",
        "similarity",
        "matrix",
        "based",
        "on",
        "and",
        ".",
        "It",
        "then",
        "gets",
        "the",
        "new",
        "expression",
        "for",
        "and",
        "with",
        "the",
        "equation",
        "below",
        ":",
        "where",
        "and",
        "represent",
        "the",
        "weighted",
        "summation",
        "of",
        "and",
        ".",
        "It",
        "further",
        "enhances",
        "the",
        "local",
        "inference",
        "information",
        "collected",
        "as",
        "below",
        ".",
        "After",
        "the",
        "enhancement",
        "of",
        "local",
        "inference",
        ",",
        "another",
        "Bi",
        "-",
        "LSTM",
        "layer",
        "is",
        "used",
        "to",
        "capture",
        "local",
        "inference",
        "information",
        "and",
        "their",
        "context",
        "for",
        "inference",
        "composition",
        ".",
        "Instead",
        "of",
        "summation",
        "adopted",
        "by",
        "Parikh",
        "et",
        "al",
        ".",
        ",",
        "ESIM",
        "proposes",
        "to",
        "compute",
        "both",
        "max",
        "and",
        "average",
        "pooling",
        "and",
        "feeds",
        "the",
        "concatenate",
        "fixed",
        "length",
        "vector",
        "to",
        "the",
        "final",
        "classifier",
        ":",
        "a",
        "fully",
        "connected",
        "multi",
        "-",
        "layer",
        "perceptron",
        ".",
        "Figure",
        "[",
        "reference",
        "]",
        "shows",
        "a",
        "high",
        "-",
        "level",
        "view",
        "of",
        "the",
        "ESIM",
        "architecture",
        ",",
        "where",
        "the",
        "bottom",
        "LSTM1",
        "layer",
        "of",
        "Figure",
        "[",
        "reference",
        "]",
        "is",
        "the",
        "input",
        "encoding",
        "layer",
        ",",
        "the",
        "middle",
        "part",
        "with",
        "LSTM2",
        "layer",
        "is",
        "the",
        "local",
        "inference",
        "layer",
        ",",
        "the",
        "upper",
        "part",
        "is",
        "the",
        "inference",
        "composition",
        "layer",
        ".",
        "subsection",
        ":",
        "aESIM",
        "model",
        "The",
        "overall",
        "architecture",
        "of",
        "our",
        "newly",
        "proposed",
        "attention",
        "boosted",
        "sequential",
        "inference",
        "model",
        "(",
        "named",
        "aESIM",
        ")",
        "based",
        "on",
        "ESIM",
        "is",
        "similar",
        "to",
        "ESIM",
        ".",
        "In",
        "detail",
        ",",
        "aESIM",
        "also",
        "consists",
        "of",
        "four",
        "main",
        "parts",
        ":",
        "encoding",
        "layer",
        ",",
        "local",
        "inference",
        "modeling",
        "layer",
        ",",
        "decoding",
        "layer",
        "and",
        "classification",
        "layer",
        ".",
        "The",
        "only",
        "difference",
        "between",
        "ESIM",
        "and",
        "aESIM",
        "is",
        "that",
        "we",
        "substitute",
        "the",
        "two",
        "Bi",
        "-",
        "LSTM",
        "layers",
        "(",
        "LSTM1",
        "and",
        "LSTM2",
        ")",
        "in",
        "ESIM",
        "with",
        "two",
        "Bi",
        "-",
        "aLSTM",
        "layers",
        "in",
        "aESIM",
        ".",
        "Therefore",
        ",",
        "as",
        "illustrated",
        "in",
        "Figure",
        "[",
        "reference",
        "]",
        ",",
        "the",
        "layers",
        "with",
        "red",
        "-",
        "dotted",
        "circles",
        "in",
        "ESIM",
        "will",
        "be",
        "replaced",
        "by",
        "the",
        "Bi",
        "-",
        "aLSTM",
        "layers",
        "shown",
        "in",
        "the",
        "right",
        "upper",
        "corner",
        "of",
        "the",
        "Figure",
        "[",
        "reference",
        "]",
        "and",
        "the",
        "details",
        "of",
        "Bi",
        "-",
        "aLSTM",
        "can",
        "be",
        "found",
        "in",
        "Figure",
        "[",
        "reference",
        "]",
        ".",
        "Given",
        "the",
        "word",
        "vector",
        "of",
        "the",
        "-",
        "th",
        "word",
        "in",
        "sentence",
        ",",
        "which",
        "can",
        "be",
        "obtained",
        "by",
        "pre",
        "-",
        "trained",
        "word",
        "embeddings",
        "such",
        "as",
        "Glove",
        "840B",
        "vectors",
        "in",
        "the",
        "first",
        "Bi",
        "-",
        "aLSTM",
        "layer",
        "or",
        "obtained",
        "from",
        "the",
        "local",
        "inference",
        "modeling",
        "layer",
        "in",
        "the",
        "second",
        "Bi",
        "-",
        "aLSTM",
        "layer",
        ".",
        "We",
        "utilize",
        "a",
        "forward",
        "LSTM",
        "layer",
        "and",
        "a",
        "backward",
        "LSTM",
        "layer",
        "to",
        "collect",
        "both",
        "direction",
        "information",
        "and",
        ".",
        "As",
        "described",
        "in",
        "introduction",
        "section",
        ",",
        "in",
        "the",
        "following",
        "newly",
        "proposed",
        "Bi",
        "-",
        "aLSTM",
        ",",
        "we",
        "add",
        "word",
        "attention",
        "and",
        "additive",
        "operation",
        "on",
        "both",
        "orientations",
        "of",
        "traditional",
        "Bi",
        "-",
        "LSTM",
        "layer",
        ".",
        "Word",
        "attention",
        "layer",
        "It",
        "\u2019s",
        "obvious",
        "that",
        "not",
        "all",
        "words",
        "contribute",
        "equally",
        "to",
        "the",
        "representation",
        "of",
        "a",
        "sentence",
        ".",
        "Attention",
        "mechanism",
        ",",
        "which",
        "is",
        "introduced",
        "in",
        ",",
        "is",
        "extremely",
        "effective",
        "to",
        "extract",
        "vital",
        "words",
        "from",
        "the",
        "whole",
        "sentence",
        ",",
        "and",
        "is",
        "particularly",
        "beneficial",
        "to",
        "generate",
        "the",
        "sentence",
        "vector",
        ".",
        "Therefore",
        ",",
        "we",
        "use",
        "the",
        "following",
        "attention",
        "mechanism",
        "after",
        "we",
        "get",
        "and",
        ".",
        "Suppose",
        ",",
        "we",
        "then",
        "have",
        "where",
        "is",
        "obtained",
        "after",
        "one",
        "-",
        "layer",
        "MLP",
        "for",
        "the",
        "input",
        ",",
        "is",
        "the",
        "importance",
        "of",
        "word",
        ",",
        "is",
        "calculated",
        "by",
        "the",
        "SoftMax",
        "unit",
        "on",
        "the",
        "context",
        "vector",
        "of",
        "the",
        "sentence",
        "which",
        "is",
        "randomly",
        "initialized",
        "and",
        "modified",
        "during",
        "the",
        "training",
        ",",
        "is",
        "the",
        "attention",
        "enhanced",
        "vector",
        "through",
        "multiplying",
        "the",
        "weight",
        "and",
        "original",
        "vector",
        ",",
        "where",
        "correspond",
        "to",
        "the",
        "forward",
        "vector",
        "and",
        "the",
        "backward",
        "vector",
        ",",
        "respectively",
        ".",
        "Adaptive",
        "word",
        "direction",
        "layer",
        "In",
        "traditional",
        "Bi",
        "-",
        "LSTM",
        "model",
        ",",
        "the",
        "forward",
        "and",
        "the",
        "backward",
        "vectors",
        "of",
        "a",
        "word",
        "are",
        "considered",
        "to",
        "have",
        "equal",
        "importance",
        "on",
        "the",
        "word",
        "representation",
        ".",
        "The",
        "model",
        "simply",
        "connects",
        "the",
        "forward",
        "and",
        "backward",
        "vectors",
        "head",
        "and",
        "tail",
        "without",
        "weighing",
        "their",
        "importance",
        ".",
        "For",
        "a",
        "word",
        "in",
        "different",
        "direction",
        "or",
        "orientation",
        ",",
        "the",
        "former",
        "and",
        "the",
        "latter",
        "words",
        "are",
        "reversed",
        ".",
        "Thus",
        ",",
        "different",
        "direction",
        "vectors",
        "of",
        "a",
        "word",
        "make",
        "different",
        "contribution",
        "to",
        "the",
        "representation",
        ",",
        "especially",
        "the",
        "words",
        "in",
        "a",
        "long",
        "sentence",
        ".",
        "Therefore",
        ",",
        "we",
        "propose",
        "a",
        "new",
        "adaptive",
        "direction",
        "layer",
        "to",
        "learn",
        "the",
        "contribution",
        "of",
        "different",
        "directions",
        "for",
        "a",
        "single",
        "word",
        ".",
        "Formally",
        ",",
        "given",
        "two",
        "direction",
        "word",
        "vectors",
        "and",
        ",",
        "the",
        "whole",
        "word",
        "vector",
        "can",
        "be",
        "expressed",
        "as",
        ":",
        "where",
        ",",
        "and",
        "denote",
        "weight",
        "matrix",
        "and",
        "the",
        "bias",
        ",",
        "denotes",
        "the",
        "nonlinear",
        "function",
        ",",
        "denotes",
        "the",
        "concentration",
        ".",
        "All",
        "the",
        "parameters",
        "can",
        "be",
        "learned",
        "during",
        "training",
        ".",
        "Then",
        "we",
        "can",
        "get",
        "the",
        "whole",
        "sentence",
        "vector",
        "as",
        "below",
        ":",
        "This",
        "word",
        "and",
        "orientation",
        "enhanced",
        "Bi",
        "-",
        "LSTM",
        "is",
        "called",
        "Bi",
        "-",
        "aLSTM",
        ".",
        "Its",
        "whole",
        "architecture",
        "is",
        "shown",
        "in",
        "the",
        "Figure",
        "[",
        "reference",
        "]",
        ",",
        "is",
        "applied",
        "in",
        "ESIM",
        "model",
        "to",
        "replace",
        "the",
        "two",
        "Bi",
        "-",
        "LSTM",
        "layers",
        "for",
        "the",
        "task",
        "of",
        "natural",
        "language",
        "inference",
        ".",
        "Besides",
        ",",
        "this",
        "Bi",
        "-",
        "aLSTM",
        "can",
        "be",
        "used",
        "to",
        "other",
        "natural",
        "language",
        "processing",
        "tasks",
        "and",
        "our",
        "preliminary",
        "experiments",
        "have",
        "demonstrated",
        "that",
        "Bi",
        "-",
        "aLSTM",
        "is",
        "capable",
        "of",
        "improving",
        "the",
        "performance",
        "of",
        "Bi",
        "-",
        "LSTM",
        "models",
        "on",
        "sentimental",
        "classification",
        "task",
        "(",
        "for",
        "space",
        "limitation",
        ",",
        "this",
        "results",
        "will",
        "not",
        "be",
        "shown",
        "in",
        "the",
        "paper",
        ")",
        ".",
        "section",
        ":",
        "Experiment",
        "Setup",
        "subsection",
        ":",
        "Datasets",
        "We",
        "evaluated",
        "our",
        "model",
        "on",
        "three",
        "datasets",
        ":",
        "the",
        "Stanford",
        "Natural",
        "Language",
        "Inference",
        "(",
        "SNLI",
        ")",
        "corpus",
        ",",
        "the",
        "Multi",
        "-",
        "Genre",
        "Natural",
        "Language",
        "Inference",
        "(",
        "MultiNLI",
        ")",
        "corpus",
        ",",
        "and",
        "Quora",
        "duplicate",
        "question",
        "dataset",
        ".",
        "We",
        "selected",
        "these",
        "three",
        "relatively",
        "large",
        "corpora",
        "out",
        "of",
        "eight",
        "corpora",
        "in",
        "since",
        "deep",
        "learning",
        "models",
        "usually",
        "show",
        "better",
        "generalization",
        "ability",
        "on",
        "large",
        "training",
        "sets",
        "and",
        "produce",
        "more",
        "convincing",
        "results",
        "than",
        "on",
        "small",
        "training",
        "sets",
        ".",
        "SNLI",
        "The",
        "Stanford",
        "Natural",
        "Language",
        "Inference",
        "(",
        "SNLI",
        ")",
        "corpus",
        "contains",
        "570",
        ",",
        "152",
        "sentence",
        "pairs",
        ",",
        "including",
        "549",
        "K",
        "training",
        "pairs",
        ",",
        "10",
        "K",
        "validation",
        "pairs",
        "and",
        "10",
        "K",
        "testing",
        "pairs",
        ".",
        "Each",
        "pair",
        "has",
        "one",
        "of",
        "relation",
        "classes",
        "(",
        "entailment",
        ",",
        "neutral",
        ",",
        "contradiction",
        "and",
        "\u2018",
        "-",
        "\u2019",
        ")",
        ".",
        "The",
        "\u2018",
        "-",
        "\u2019",
        "class",
        "indicates",
        "there",
        "is",
        "no",
        "conclusion",
        "between",
        "the",
        "two",
        "sentences",
        ".",
        "Consequently",
        ",",
        "we",
        "remove",
        "all",
        "pairs",
        "with",
        "relation",
        "\u2019",
        "-",
        "\u2019",
        "during",
        "training",
        ",",
        "validating",
        "and",
        "testing",
        "processes",
        ".",
        "MultiNLI",
        "This",
        "corpus",
        "is",
        "a",
        "crowd",
        "-",
        "sourced",
        "collection",
        "of",
        "433",
        "K",
        "sentence",
        "pairs",
        "annotated",
        "with",
        "textual",
        "entailment",
        "information",
        ".",
        "The",
        "corpus",
        "is",
        "modeled",
        "on",
        "the",
        "SNLI",
        "corpus",
        ",",
        "but",
        "differs",
        "in",
        "that",
        "covers",
        "a",
        "range",
        "of",
        "genres",
        "of",
        "spoken",
        "and",
        "written",
        "text",
        ",",
        "and",
        "supports",
        "a",
        "distinctive",
        "cross",
        "-",
        "genre",
        "generation",
        "evaluation",
        ".",
        "Quora",
        "The",
        "Quora",
        "dataset",
        "contains",
        "400",
        ",",
        "000",
        "question",
        "pairs",
        ".",
        "The",
        "task",
        "of",
        "this",
        "corpus",
        "is",
        "to",
        "judge",
        "whether",
        "the",
        "two",
        "sentences",
        "means",
        "the",
        "same",
        "affair",
        ".",
        "subsection",
        ":",
        "Setting",
        "We",
        "use",
        "the",
        "validation",
        "set",
        "to",
        "select",
        "models",
        "for",
        "testing",
        ".",
        "The",
        "hyper",
        "-",
        "parameters",
        "of",
        "aESIM",
        "model",
        "are",
        "listed",
        "as",
        "follows",
        ".",
        "We",
        "use",
        "the",
        "Adam",
        "method",
        "for",
        "optimization",
        ".",
        "The",
        "first",
        "momentum",
        "is",
        "set",
        "to",
        "be",
        "0.9",
        "and",
        "the",
        "second",
        "0.999",
        ".",
        "The",
        "initial",
        "learning",
        "rate",
        "is",
        "set",
        "to",
        "0.0005",
        ",",
        "and",
        "the",
        "batch",
        "size",
        "is",
        "128",
        ".",
        "The",
        "dimensions",
        "of",
        "all",
        "hidden",
        "states",
        "of",
        "Bi",
        "-",
        "aLSTM",
        "and",
        "word",
        "embedding",
        "are",
        "300",
        ".",
        "We",
        "employ",
        "non",
        "-",
        "linearity",
        "function",
        "replacing",
        "rectified",
        "linear",
        "unit",
        "on",
        "account",
        "of",
        "its",
        "faster",
        "convergence",
        "rate",
        ".",
        "Dropout",
        "rate",
        "is",
        "set",
        "to",
        "0.2",
        "during",
        "training",
        ".",
        "We",
        "use",
        "pre",
        "-",
        "trained",
        "300",
        "-",
        "D",
        "Glove",
        "840B",
        "vectors",
        "to",
        "initialize",
        "word",
        "embeddings",
        ".",
        "Out",
        "-",
        "of",
        "-",
        "vocabulary",
        "(",
        "OOV",
        ")",
        "words",
        "are",
        "initialized",
        "randomly",
        "with",
        "Gaussian",
        "samples",
        ".",
        "All",
        "vectors",
        "are",
        "updated",
        "during",
        "training",
        ".",
        "subsection",
        ":",
        "Experiment",
        "results",
        "Except",
        "for",
        "comparing",
        "our",
        "method",
        "aESIM",
        "with",
        "ESIM",
        ",",
        "we",
        "listed",
        "the",
        "experimental",
        "results",
        "of",
        "methods",
        "with",
        "their",
        "references",
        "in",
        "Table",
        "[",
        "reference",
        "]",
        "on",
        "SNIL",
        ".",
        "In",
        "Table",
        "[",
        "reference",
        "]",
        ",",
        "the",
        "method",
        "in",
        "the",
        "first",
        "block",
        "is",
        "a",
        "traditional",
        "feature",
        "engineering",
        "method",
        ",",
        "those",
        "in",
        "the",
        "second",
        "are",
        "the",
        "sentence",
        "vector",
        "-",
        "based",
        "models",
        ",",
        "those",
        "in",
        "the",
        "third",
        "are",
        "attention",
        "-",
        "based",
        "models",
        ",",
        "and",
        "ESIM",
        "and",
        "our",
        "aESIM",
        "are",
        "shown",
        "in",
        "the",
        "fourth",
        "block",
        ".",
        "Where",
        "the",
        "results",
        "of",
        "ESIM",
        "and",
        "aESIM",
        "are",
        "implemented",
        "by",
        "ourselves",
        "on",
        "Keras",
        ",",
        "the",
        "results",
        "of",
        "the",
        "others",
        "are",
        "taken",
        "from",
        "their",
        "original",
        "publications",
        ".",
        "We",
        "then",
        "compare",
        "the",
        "baseline",
        "models",
        ",",
        "CBOW",
        ",",
        "Bi",
        "-",
        "LSTM",
        "with",
        "ESIM",
        "and",
        "our",
        "aESIM",
        "on",
        "MultiNLI",
        "corpus",
        "shown",
        "In",
        "Table",
        "[",
        "reference",
        "]",
        ",",
        "where",
        "the",
        "results",
        "of",
        "the",
        "baselines",
        "are",
        "taken",
        "from",
        ".",
        "Finally",
        ",",
        "we",
        "compare",
        "several",
        "types",
        "of",
        "CNN",
        "and",
        "RNN",
        "models",
        "on",
        "Quroa",
        "corpus",
        "shown",
        "in",
        "Table",
        "[",
        "reference",
        "]",
        ",",
        "the",
        "results",
        "of",
        "theses",
        "CNN",
        "and",
        "RNN",
        "models",
        "are",
        "taken",
        "from",
        ".",
        "The",
        "accuracy",
        "(",
        "ACC",
        ")",
        "of",
        "each",
        "method",
        "is",
        "measured",
        "by",
        "the",
        "commonly",
        "used",
        "precision",
        "score",
        ",",
        "and",
        "the",
        "methods",
        "with",
        "the",
        "best",
        "accuracy",
        "are",
        "marked",
        "in",
        "bold",
        ".",
        "According",
        "to",
        "the",
        "results",
        "in",
        "Tables",
        "2",
        "-",
        "4",
        ",",
        "aESIM",
        "model",
        "achieved",
        "88.1",
        "%",
        "on",
        "SNLI",
        "corpus",
        ",",
        "elevating",
        "0.8",
        "percent",
        "higher",
        "than",
        "ESIM",
        "model",
        ".",
        "It",
        "promoted",
        "almost",
        "0.5",
        "percent",
        "accuracy",
        "and",
        "outperformed",
        "the",
        "baselines",
        "on",
        "MultiNLI",
        ".",
        "It",
        "also",
        "achieved",
        "88.01",
        "%",
        "on",
        "Quora",
        ".",
        "Therefore",
        ",",
        "we",
        "concluded",
        "that",
        "aESIM",
        "with",
        "further",
        "word",
        "attention",
        "and",
        "word",
        "orientation",
        "operation",
        "was",
        "superior",
        "to",
        "ESIM",
        "model",
        ".",
        "subsection",
        ":",
        "Attention",
        "visualization",
        "We",
        "selected",
        "three",
        "types",
        "of",
        "sentence",
        "pairs",
        "from",
        "a",
        "premise",
        "and",
        "its",
        "three",
        "hypothesis",
        "sentences",
        "in",
        "the",
        "test",
        "set",
        "of",
        "SNLI",
        "corpus",
        "as",
        "shown",
        "in",
        "Figure",
        "[",
        "reference",
        "]",
        ",",
        "where",
        "the",
        "premise",
        "sentence",
        "is",
        "\u2018",
        "A",
        "woman",
        "with",
        "a",
        "green",
        "headscarf",
        ",",
        "blue",
        "shirt",
        "and",
        "a",
        "very",
        "big",
        "grin",
        "\u2019",
        ",",
        "and",
        "three",
        "hypothesis",
        "sentences",
        "are",
        "\u2018",
        "the",
        "woman",
        "has",
        "been",
        "shot",
        "\u2019",
        ",",
        "\u2018",
        "the",
        "woman",
        "is",
        "very",
        "happy",
        "\u2019",
        "and",
        "\u2018",
        "the",
        "woman",
        "is",
        "young",
        "\u2019",
        "with",
        "relation",
        "labels",
        "\u2018",
        "contradiction",
        "\u2019",
        ",",
        "\u2018",
        "entailment",
        "\u2019",
        ",",
        "and",
        "\u2018",
        "neutral",
        "\u2019",
        ",",
        "respectively",
        ".",
        "Each",
        "pair",
        "of",
        "sentences",
        "has",
        "their",
        "key",
        "word",
        "pairs",
        ":",
        "grin",
        "-",
        "shot",
        ",",
        "grin",
        "-",
        "happy",
        "and",
        "grin",
        "-",
        "young",
        ",",
        "which",
        "determines",
        "whether",
        "the",
        "premise",
        "can",
        "entail",
        "the",
        "hypothesis",
        ".",
        "Figures",
        "4.a",
        "-",
        "4.c",
        "are",
        "the",
        "visualization",
        "of",
        "the",
        "attention",
        "layer",
        "between",
        "sentence",
        "pairs",
        "after",
        "the",
        "Bi",
        "-",
        "LSTM",
        "layer",
        "in",
        "ESIM",
        "model",
        "and",
        "that",
        "after",
        "Bi",
        "-",
        "aLSTM",
        "layer",
        "in",
        "aESIM",
        "model",
        "for",
        "contrasting",
        "ESIM",
        "and",
        "aESIM",
        ".",
        "By",
        "doing",
        "so",
        ",",
        "we",
        "could",
        "understand",
        "how",
        "the",
        "models",
        "judge",
        "the",
        "relation",
        "between",
        "two",
        "sentences",
        ".",
        "In",
        "each",
        "Figure",
        ",",
        "the",
        "brighter",
        "the",
        "color",
        ",",
        "the",
        "higher",
        "the",
        "weight",
        "is",
        ".",
        "We",
        "could",
        "conclude",
        "that",
        "our",
        "aESIM",
        "model",
        "had",
        "the",
        "higher",
        "weight",
        "than",
        "ESIM",
        "model",
        "on",
        "each",
        "key",
        "word",
        "pair",
        ",",
        "especially",
        "in",
        "Figure",
        "[",
        "reference",
        "]",
        ".b",
        ",",
        "where",
        "the",
        "similarity",
        "of",
        "\u2018",
        "happy",
        "\u2019",
        "and",
        "\u2018",
        "grin",
        "\u2019",
        "in",
        "aESIM",
        "model",
        "is",
        "much",
        "higher",
        "than",
        "that",
        "in",
        "ESIM",
        "model",
        ".",
        "Therefore",
        ",",
        "our",
        "aESIM",
        "model",
        "was",
        "able",
        "to",
        "capture",
        "the",
        "most",
        "important",
        "word",
        "pair",
        "in",
        "each",
        "pair",
        "of",
        "sentences",
        ".",
        "section",
        ":",
        "Conclusion",
        "In",
        "this",
        "study",
        ",",
        "we",
        "propose",
        "an",
        "improved",
        "version",
        "of",
        "ESIM",
        "named",
        "aESIM",
        "for",
        "NLI",
        ".",
        "It",
        "modifies",
        "the",
        "Bi",
        "-",
        "LSTM",
        "layer",
        "to",
        "collect",
        "more",
        "information",
        ".",
        "We",
        "evaluate",
        "our",
        "aESIM",
        "model",
        "on",
        "three",
        "NLI",
        "corpora",
        ".",
        "Experimental",
        "results",
        "show",
        "that",
        "aESIM",
        "model",
        "achieves",
        "better",
        "performance",
        "than",
        "ESIM",
        "model",
        ".",
        "In",
        "the",
        "future",
        ",",
        "we",
        "will",
        "evaluate",
        "how",
        "attention",
        "mechanisms",
        "can",
        "be",
        "applied",
        "on",
        "other",
        "tasks",
        "and",
        "explore",
        "a",
        "way",
        "to",
        "use",
        "less",
        "time",
        "and",
        "space",
        "with",
        "guaranteed",
        "accuracy",
        ".",
        "section",
        ":",
        "Acknowledgement",
        "This",
        "work",
        "is",
        "supported",
        "in",
        "part",
        "by",
        "the",
        "National",
        "Nature",
        "Science",
        "Foundation",
        "of",
        "China",
        "(",
        "No",
        ".",
        "61876016",
        "and",
        "No",
        ".",
        "61632004",
        ")",
        ",",
        "the",
        "Fundamental",
        "Research",
        "Funds",
        "for",
        "the",
        "Central",
        "Universities",
        "(",
        "No",
        ".",
        "2018JBZ006",
        ")",
        ".",
        "bibliography",
        ":",
        "References"
    ]
}
