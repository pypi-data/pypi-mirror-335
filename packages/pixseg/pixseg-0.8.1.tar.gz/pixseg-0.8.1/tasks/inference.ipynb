{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference model using these strategies\n",
    "\n",
    "Each technique adds significant time cost. You may play around which combos give the best balance for your specific domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRFs and Morphological Operations\n",
    "\n",
    "Refine boundaries and clean up noises\n",
    "\n",
    "Use PyDenseCRF, employ dilation and erosion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thresholding\n",
    "\n",
    "Fine tune uncertain regions around boundaries\n",
    "\n",
    "Apply threshold on logits after softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test-Time Augmentation and Multi-Scale\n",
    "\n",
    "Improve robustness and accuracy, reduce reliance on specific features\n",
    "\n",
    "Apply augmentations like flipping, rotation, scaling, etc ... Then aggregate results by max/most/mean/weighted on logits/probs/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL.Image import Image\n",
    "from torch import Tensor\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "from torchvision.transforms.v2 import functional as TF\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "from src.pixseg.datasets import *\n",
    "from src.pixseg.models import *\n",
    "from src.pixseg.pipeline import (\n",
    "    TestTimeAugmentations,\n",
    "    forward_batch,\n",
    "    inference_with_augmentations,\n",
    ")\n",
    "from src.pixseg.pipeline.test_time import (\n",
    "    blur_output,\n",
    "    morph_pred,\n",
    "    refine_prob_by_crf,\n",
    "    threshold_prob,\n",
    ")\n",
    "from src.pixseg.utils.transform import SegmentationTransform\n",
    "from src.pixseg.utils.visual import combine_images, draw_mask_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = BiSeNet_ResNet18_Weights.SBD\n",
    "model = bisenet_resnet18(weights=weights)\n",
    "transforms = SegmentationTransform()\n",
    "augment = weights.value.transforms()\n",
    "dataset = VOCSegmentation(\n",
    "    r\"..\\dataset\", image_set=\"val\", transforms=transforms, year=\"2007\"\n",
    ")\n",
    "metadata = resolve_metadata(\"VOC\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: tuple[Tensor, Tensor] = dataset[1]\n",
    "image, mask = data\n",
    "model.eval().to(device)\n",
    "with torch.no_grad():\n",
    "    images = image.unsqueeze(0)\n",
    "    logits, _ = forward_batch(model, images, None, augment, None, device)\n",
    "logit = logits[\"out\"].squeeze(0)\n",
    "prob = torch.softmax(logit, 0)\n",
    "pred = logit.argmax(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = metadata.colors\n",
    "mask_overlay = draw_mask_on_image(image, mask, colors)\n",
    "pred_overlay = draw_mask_on_image(image, pred, colors)\n",
    "snapshot = combine_images([image, mask_overlay, pred_overlay])\n",
    "snapshot_pil: Image = TF.to_pil_image(snapshot)\n",
    "display(snapshot_pil.reduce(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_overlays = []\n",
    "for i in range(0, 10, 2):\n",
    "    crf_refined = refine_prob_by_crf(prob.numpy(force=True), image, iter=i)\n",
    "    crf_pred = torch.tensor(crf_refined).argmax(0)\n",
    "    crf_overlay = draw_mask_on_image(image, crf_pred, colors)\n",
    "    crf_overlays.append(crf_overlay)\n",
    "\n",
    "crf_snapshot = combine_images(crf_overlays)\n",
    "crf_snapshot_pil: Image = TF.to_pil_image(crf_snapshot)\n",
    "display(crf_snapshot_pil.reduce(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_overlays = []\n",
    "for i in range(5):\n",
    "    std = i / 10 + 0.5\n",
    "    blur_logit = blur_output(logit.numpy(force=True), std)\n",
    "    blur_pred = torch.tensor(blur_logit).argmax(0)\n",
    "    blur_overlay = draw_mask_on_image(image, blur_pred, colors)\n",
    "    blur_overlays.append(blur_overlay)\n",
    "\n",
    "blur_snapshot = combine_images(blur_overlays)\n",
    "blur_snapshot_pil: Image = TF.to_pil_image(blur_snapshot)\n",
    "display(blur_snapshot_pil.reduce(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation and erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_class = np.unique(pred)[1]\n",
    "print(\"Showing for class\", show_class)\n",
    "for is_dilate in [True, False]:\n",
    "    morphed_overlays = []\n",
    "    for iter in range(5, 21, 5):\n",
    "        morphed_pred = morph_pred(pred.numpy(force=True), is_dilate, iterations=iter)\n",
    "        morphed_output = torch.tensor(morphed_pred[show_class])\n",
    "        morphed_overlay = draw_segmentation_masks(\n",
    "            image, morphed_output, colors=(128, 0, 0)\n",
    "        )\n",
    "        morphed_overlays.append(morphed_overlay)\n",
    "\n",
    "    print(\"Dilation\" if is_dilate else \"Erosion\")\n",
    "    morph_snapshot = combine_images(morphed_overlays)\n",
    "    morph_snapshot_pil: Image = TF.to_pil_image(morph_snapshot)\n",
    "    display(morph_snapshot_pil.reduce(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_class = np.unique(pred)[1]\n",
    "print(\"Showing for class\", show_class)\n",
    "threshold_overlays = []\n",
    "for i in range(1, 5):\n",
    "    th = i / 5\n",
    "    threshold_preds = threshold_prob(prob.numpy(force=True), th)\n",
    "    threshold_output = torch.tensor(threshold_preds[show_class])\n",
    "    threshold_overlay = draw_segmentation_masks(\n",
    "        image, threshold_output, colors=(128, 0, 0)\n",
    "    )\n",
    "    threshold_overlays.append(threshold_overlay)\n",
    "\n",
    "threshold_snapshot = combine_images(threshold_overlays)\n",
    "threshold_snapshot_pil: Image = TF.to_pil_image(threshold_snapshot)\n",
    "display(threshold_snapshot_pil.reduce(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prelim_images, _ = augment(images.to(device), None)\n",
    "ttas = TestTimeAugmentations(\n",
    "    (0.75, 1, 1.25), (False, True), (False,), (-15, 0, 15), iter_product=True\n",
    ")\n",
    "augmented_logits = inference_with_augmentations(model, prelim_images, ttas)\n",
    "\n",
    "print(\"Augmented results in order\", ttas.augment_combos)\n",
    "augmented_overlays = []\n",
    "for i in range(augmented_logits.size(0)):\n",
    "    augmented_pred = augmented_logits[i, 0].argmax(0)\n",
    "    augmented_overlay = draw_mask_on_image(image, augmented_pred, colors)\n",
    "    augmented_overlays.append(augmented_overlay)\n",
    "overlays = combine_images(augmented_overlays)\n",
    "overlays_pil: Image = TF.to_pil_image(overlays)\n",
    "display(overlays_pil.reduce(3))\n",
    "\n",
    "# mean of logits\n",
    "aggregated_logits = torch.mean(augmented_logits, dim=0)\n",
    "multilogits_preds = aggregated_logits.argmax(1)\n",
    "multilogits_overlay = draw_mask_on_image(image, multilogits_preds[0], colors)\n",
    "\n",
    "# max of probs (=== max of logits)\n",
    "augmented_probs = torch.softmax(augmented_logits, dim=2)\n",
    "aggregated_probs = torch.max(augmented_probs, dim=0).values\n",
    "multiprobs_preds = aggregated_probs.argmax(1)\n",
    "multiprobs_overlay = draw_mask_on_image(image, multiprobs_preds[0], colors)\n",
    "\n",
    "# mode of preds\n",
    "augmented_preds = augmented_logits.argmax(dim=2)\n",
    "aggregated_preds = torch.mode(augmented_preds, dim=0).values\n",
    "multipreds_overlay = draw_mask_on_image(image, aggregated_preds[0], colors)\n",
    "\n",
    "print(\"Aggregation by mean of logits VS by max of probs VS by mode of preds\")\n",
    "multi_snapshot = combine_images(\n",
    "    [multilogits_overlay, multiprobs_overlay, multipreds_overlay]\n",
    ")\n",
    "multi_snapshot_pil: Image = TF.to_pil_image(multi_snapshot)\n",
    "display(multi_snapshot_pil.reduce(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
