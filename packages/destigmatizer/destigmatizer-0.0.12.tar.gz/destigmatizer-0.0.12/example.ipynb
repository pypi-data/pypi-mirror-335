{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reframe Package Example Notebook\n",
    "\n",
    "This notebook demonstrates the core functionality of the Reframe package for analyzing and rewriting drug-related and stigmatizing content.\n",
    "\n",
    "## Features demonstrated:\n",
    "1. Classifying drug-related content\n",
    "2. Identifying stigmatizing language\n",
    "3. Analyzing text style\n",
    "4. Rewriting stigmatizing content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the destigmatizer package and its components\n",
    "from destigmatizer import core\n",
    "from destigmatizer.clients import get_client\n",
    "from destigmatizer.utils import get_default_model, get_model_mapping\n",
    "\n",
    "# Define example texts for demonstration\n",
    "NON_DRUG_POST = \"I think we should really work on the housing crisis in urban areas. The homeless are getting scary.\"\n",
    "DRUG_NON_STIGMA_POST = \"I really feel for people who suffer from substance use disorder, being unable to control an impulse due to dependency sounds scary.\"\n",
    "DRUG_AND_STIGMA_POST = \"Addicts really need to get control of themselves. Just stop doing drugs. It seems like these people are just lacking willpower.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API Client\n",
    "\n",
    "First, we need to initialize the client with your API key. This example uses OpenAI, but you could use other clients as supported by the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client initialized with model: gpt-4o-2024-11-20\n"
     ]
    }
   ],
   "source": [
    "# Initialize with your API key\n",
    "# You can either load from a secrets file or directly input your key\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Option 1: Load from secrets file\n",
    "try:\n",
    "    with open('./secrets.json') as f:\n",
    "        secrets = json.load(f)\n",
    "    api_key = secrets.get('OPENAI_API_KEY')\n",
    "except (FileNotFoundError, json.JSONDecodeError, KeyError):\n",
    "    # Option 2: Get from environment variable\n",
    "    api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize client\n",
    "client = get_client('openai', api_key=api_key)\n",
    "# model = get_default_model('openai')  # Get default model for this client type\n",
    "model = \"gpt-4o-2024-11-20\"\n",
    "print(f\"Client initialized with model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize with your API key\n",
    "# # You can either load from a secrets file or directly input your key\n",
    "\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# # Option 1: Load from secrets file\n",
    "# try:\n",
    "#     with open('./secrets.json') as f:\n",
    "#         secrets = json.load(f)\n",
    "#     api_key = secrets.get('TOGETHER_API_KEY')\n",
    "# except (FileNotFoundError, json.JSONDecodeError, KeyError):\n",
    "#     # Option 2: Get from environment variable\n",
    "#     api_key = os.environ.get('TOGETHER_API_KEY')\n",
    "\n",
    "# # Initialize client\n",
    "# client = get_client('together', api_key=api_key)\n",
    "# model = get_model_mapping(\"medium\", 'together')  # Get default model for this client type\n",
    "# print(f\"Client initialized with model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize with your API key\n",
    "# # You can either load from a secrets file or directly input your key\n",
    "\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# # Option 1: Load from secrets file\n",
    "# try:\n",
    "#     with open('./secrets.json') as f:\n",
    "#         secrets = json.load(f)\n",
    "#     api_key = secrets.get('ANTHROPIC_API_KEY')\n",
    "# except (FileNotFoundError, json.JSONDecodeError, KeyError):\n",
    "#     # Option 2: Get from environment variable\n",
    "#     api_key = os.environ.get('ANTHROPIC_API_KEY')\n",
    "\n",
    "# # Initialize client\n",
    "# client = get_client('claude', api_key=api_key)\n",
    "# model = get_model_mapping(\"medium\", 'claude')  # Get default model for this client type\n",
    "# print(f\"Client initialized with model: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended user config path: /Users/guomuqi/.reframe/config.json\n",
      "\n",
      "Loading configuration...\n",
      "\n",
      "Current configuration:\n",
      "default_config_name: medium_quality\n",
      "model_mappings:\n",
      "  small:\n",
      "    openai: gpt-4o-mini\n",
      "    together: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\n",
      "    claude: claude-3-haiku-20241022\n",
      "    ollama: llama3:8b\n",
      "    gemini: gemini-1.0-pro-001\n",
      "  medium:\n",
      "    openai: gpt-4o\n",
      "    together: meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\n",
      "    claude: claude-3-5-sonnet-20240620\n",
      "    ollama: llama3:70b\n",
      "    gemini: gemini-1.5-pro-001\n",
      "  large:\n",
      "    openai: gpt-4o-2024-05-13\n",
      "    together: mistralai/Mixtral-8x22B-Instruct-v0.1\n",
      "    claude: claude-3-opus-20240229\n",
      "    ollama: mixtral\n",
      "    gemini: gemini-1.5-flash-001\n",
      "default_models:\n",
      "  openai: gpt-4o\n",
      "  together: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\n",
      "  claude: claude-3-5-haiku-20241022\n",
      "  ollama: llama3:8b\n",
      "  gemini: gemini-1.0-pro-001\n",
      "named_configs:\n",
      "  high_quality:\n",
      "    model_name: large\n",
      "    temperature: 0.0\n",
      "    max_tokens: 4000\n",
      "    top_p: 1.0\n",
      "  medium_quality:\n",
      "    model_name: medium\n",
      "    temperature: 0.0\n",
      "    max_tokens: 2000\n",
      "    top_p: 1.0\n",
      "  low_quality:\n",
      "    model_name: small\n",
      "    temperature: 0.0\n",
      "    max_tokens: 1000\n",
      "    top_p: 1.0\n",
      "  creative:\n",
      "    model_name: medium\n",
      "    temperature: 0.7\n",
      "    max_tokens: 2000\n",
      "    top_p: 0.9\n",
      "  highly_creative:\n",
      "    model_name: medium\n",
      "    temperature: 0.9\n",
      "    max_tokens: 2500\n",
      "    top_p: 0.95\n",
      "    frequency_penalty: 0.2\n",
      "\n",
      "Adding custom configuration...\n",
      "Configuration saved to ./reframe_example_config.json\n",
      "\n",
      "Updated configuration:\n",
      "model_name: medium\n",
      "temperature: 0.9\n",
      "max_tokens: 2500\n",
      "top_p: 0.95\n",
      "frequency_penalty: 0.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from destigmatizer.config_manager import get_user_config_path, create_default_config, load_config, add_named_config, save_config, display_config\n",
    "\n",
    "# Get the recommended location for user configuration\n",
    "user_config_path = get_user_config_path()\n",
    "print(f\"Recommended user config path: {user_config_path}\")\n",
    "\n",
    "# Create a default configuration if it doesn't exist\n",
    "config_example_path = \"./reframe_example_config.json\"\n",
    "if not os.path.exists(config_example_path):\n",
    "    print(\"\\nCreating example configuration file...\")\n",
    "    create_default_config(config_example_path, overwrite=True)\n",
    "\n",
    "# Load the configuration\n",
    "print(\"\\nLoading configuration...\")\n",
    "config = load_config(config_example_path)\n",
    "\n",
    "# Display the current configuration\n",
    "print(\"\\nCurrent configuration:\")\n",
    "display_config(config)\n",
    "\n",
    "# Add a custom configuration for creative writing\n",
    "print(\"\\nAdding custom configuration...\")\n",
    "config = add_named_config(\n",
    "    config,\n",
    "    name=\"highly_creative\",\n",
    "    model_name=\"medium\",\n",
    "    temperature=0.9,\n",
    "    max_tokens=2500,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0.2\n",
    ")\n",
    "\n",
    "# Save the modified configuration\n",
    "save_config(config, config_example_path)\n",
    "\n",
    "# Display the updated configuration\n",
    "print(\"\\nUpdated configuration:\")\n",
    "display_config(config[\"named_configs\"][\"highly_creative\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Texts\n",
    "\n",
    "Let's take a look at our example texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON_DRUG_POST:\n",
      "I think we should really work on the housing crisis in urban areas. The homeless are getting scary.\n",
      "\n",
      "DRUG_NON_STIGMA_POST:\n",
      "I really feel for people who suffer from substance use disorder, being unable to control an impulse due to dependency sounds scary.\n",
      "\n",
      "DRUG_AND_STIGMA_POST:\n",
      "Addicts really need to get control of themselves. Just stop doing drugs. It seems like these people are just lacking willpower.\n"
     ]
    }
   ],
   "source": [
    "# Display the example texts\n",
    "print(\"NON_DRUG_POST:\")\n",
    "print(NON_DRUG_POST)\n",
    "print(\"\\nDRUG_NON_STIGMA_POST:\")\n",
    "print(DRUG_NON_STIGMA_POST)\n",
    "print(\"\\nDRUG_AND_STIGMA_POST:\")\n",
    "print(DRUG_AND_STIGMA_POST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classifying Drug-Related Content\n",
    "\n",
    "Let's classify texts to determine if they're related to drugs or substance use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying drug content for: \"I think we should really work on the housing crisi...\"\n",
      "Drug classification result: nd\n",
      "\n",
      "Classifying drug content for: \"Addicts really need to get control of themselves. ...\"\n",
      "Drug classification result: d\n",
      "\n",
      "Classifying drug content for: \"I really feel for people who suffer from substance...\"\n",
      "Drug classification result: nd\n"
     ]
    }
   ],
   "source": [
    "# Classify the non-drug post\n",
    "print(f\"Classifying drug content for: \\\"{NON_DRUG_POST[:50]}...\\\"\")\n",
    "non_drug_result = core.classify_if_drug(text=NON_DRUG_POST, client=client, model=model)\n",
    "print(f\"Drug classification result: {non_drug_result}\")\n",
    "\n",
    "# Classify the drug and stigma post\n",
    "print(f\"\\nClassifying drug content for: \\\"{DRUG_AND_STIGMA_POST[:50]}...\\\"\")\n",
    "drug_stigma_result = core.classify_if_drug(text=DRUG_AND_STIGMA_POST, client=client, model=model)\n",
    "print(f\"Drug classification result: {drug_stigma_result}\")\n",
    "\n",
    "# Classify the drug non-stigma post\n",
    "print(f\"\\nClassifying drug content for: \\\"{DRUG_NON_STIGMA_POST[:50]}...\\\"\")\n",
    "drug_non_stigma_result = core.classify_if_drug(text=DRUG_NON_STIGMA_POST, client=client, model=model)\n",
    "print(f\"Drug classification result: {drug_non_stigma_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identifying Stigmatizing Language\n",
    "\n",
    "Next, let's identify if texts contain stigmatizing language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying stigmatizing language for: \"I really feel for people who suffer from substance...\"\n",
      "Stigma classification result: ns\n",
      "\n",
      "Classifying stigmatizing language for: \"Addicts really need to get control of themselves. ...\"\n",
      "Stigma classification result: s, labeling: uses the term 'addicts,' which is stigmatizing and reduces individuals to their substance use, stereotyping: assumes that people with addiction lack willpower and oversimplifies the complexity of addiction, separation: implies a divide between people who use drugs and those who are perceived as having self-control, discrimination: suggests that people with addiction are at fault for their condition, potentially justifying a lack of support or empathy.\n",
      "\n",
      "Classifying stigmatizing language for: \"I think we should really work on the housing crisi...\"\n",
      "Stigma classification result: s, labeling: refers to homeless individuals in a generalized and dehumanizing way, stereotyping: implies that homeless individuals are inherently \"scary,\" which perpetuates negative assumptions, separation: creates an \"us vs. them\" dynamic by portraying homeless individuals as a threat, discrimination: suggests fear-based attitudes that could lead to exclusion or unfair treatment of homeless individuals, many of whom may struggle with substance use disorders.\n"
     ]
    }
   ],
   "source": [
    "# Classify the drug non-stigma post\n",
    "print(f\"Classifying stigmatizing language for: \\\"{DRUG_NON_STIGMA_POST[:50]}...\\\"\")\n",
    "non_stigma_result = core.classify_if_stigma(text=DRUG_NON_STIGMA_POST, client=client, model=model)\n",
    "print(f\"Stigma classification result: {non_stigma_result}\")\n",
    "\n",
    "# Classify the drug and stigma post\n",
    "print(f\"\\nClassifying stigmatizing language for: \\\"{DRUG_AND_STIGMA_POST[:50]}...\\\"\")\n",
    "stigma_result = core.classify_if_stigma(text=DRUG_AND_STIGMA_POST, client=client, model=model)\n",
    "print(f\"Stigma classification result: {stigma_result}\")\n",
    "\n",
    "# Classify the non-drug post\n",
    "print(f\"\\nClassifying stigmatizing language for: \\\"{NON_DRUG_POST[:50]}...\\\"\")\n",
    "non_drug_stigma_result = core.classify_if_stigma(text=NON_DRUG_POST, client=client, model=model)\n",
    "print(f\"Stigma classification result: {non_drug_stigma_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combined Classification\n",
    "\n",
    "Now let's classify for both drug content and stigmatizing language together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing text for drug content and stigma: \"Addicts really need to get control of themselves. ...\"\n",
      "Drug classification: d\n",
      "Stigma classification: s, labeling: uses the term 'addicts,' which is stigmatizing and reduces individuals to their substance use, stereotyping: assumes that people with addiction lack willpower and oversimplifies the complexity of addiction, separation: implies a divide between people who use drugs and those who are perceived as having self-control, discrimination: suggests that people with addiction are at fault for their condition, potentially justifying a lack of support or empathy.\n",
      "\n",
      "Analyzing text for drug content and stigma: \"I really feel for people who suffer from substance...\"\n",
      "Drug classification: nd\n",
      "Stigma classification: ns\n",
      "\n",
      "Analyzing text for drug content and stigma: \"I think we should really work on the housing crisi...\"\n",
      "Drug classification: nd\n",
      "Stigma classification: s, labeling: refers to homeless individuals in a generalized and dehumanizing way, stereotyping: implies that homeless individuals are inherently \"scary,\" which perpetuates negative assumptions, separation: creates an \"us vs. them\" dynamic by portraying homeless individuals as a threat, discrimination: suggests fear-based attitudes that could lead to exclusion or unfair treatment of homeless individuals, many of whom may struggle with substance use disorders.\n"
     ]
    }
   ],
   "source": [
    "# Perform combined classification on the drug and stigma post\n",
    "print(f\"Analyzing text for drug content and stigma: \\\"{DRUG_AND_STIGMA_POST[:50]}...\\\"\")\n",
    "\n",
    "drug_result = core.classify_if_drug(text=DRUG_AND_STIGMA_POST, client=client, model=model)\n",
    "stigma_result = core.classify_if_stigma(text=DRUG_AND_STIGMA_POST, client=client, model=model)\n",
    "\n",
    "print(f\"Drug classification: {drug_result}\")\n",
    "print(f\"Stigma classification: {stigma_result}\")\n",
    "\n",
    "# Let's analyze the non-stigma post\n",
    "print(f\"\\nAnalyzing text for drug content and stigma: \\\"{DRUG_NON_STIGMA_POST[:50]}...\\\"\")\n",
    "drug_result2 = core.classify_if_drug(text=DRUG_NON_STIGMA_POST, client=client, model=model)\n",
    "stigma_result2 = core.classify_if_stigma(text=DRUG_NON_STIGMA_POST, client=client, model=model)\n",
    "print(f\"Drug classification: {drug_result2}\")\n",
    "print(f\"Stigma classification: {stigma_result2}\")\n",
    "\n",
    "# Let's analyze the non-drug post\n",
    "print(f\"\\nAnalyzing text for drug content and stigma: \\\"{NON_DRUG_POST[:50]}...\\\"\")\n",
    "drug_result3 = core.classify_if_drug(text=NON_DRUG_POST, client=client, model=model)\n",
    "stigma_result3 = core.classify_if_stigma(text=NON_DRUG_POST, client=client, model=model)\n",
    "print(f\"Drug classification: {drug_result3}\")\n",
    "print(f\"Stigma classification: {stigma_result3}\")\n",
    "# print(f\"Combined result: ({drug_result3}, {stigma_result3})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Style Analysis\n",
    "\n",
    "Before rewriting, we can analyze the style of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text style analysis for example stigmatizing post:\n",
      "{'punctuation_usage': 'moderate, with . being most frequent', 'passive_voice_usage': 'none', 'sentence_length_variation': 'ranging from short (4 words) to long (9 words) with an average of 7.0 words per sentence', 'lexical_diversity': '123.48 (MTLD)', 'top_emotions': 'judgmental'}\n",
      "\n",
      "Text style analysis for non-stigmatizing post:\n",
      "{'punctuation_usage': 'moderate, with ,, . being most frequent', 'passive_voice_usage': 'none', 'sentence_length_variation': 'ranging from short (22 words) to long (22 words) with an average of 22.0 words per sentence', 'lexical_diversity': '135.52 (MTLD)', 'top_emotions': 'compassion'}\n"
     ]
    }
   ],
   "source": [
    "# Analyze the style of the example stigmatizing post\n",
    "example_style = core.analyze_text_llm(text=DRUG_AND_STIGMA_POST, client=client, model=model)\n",
    "print(f\"Text style analysis for example stigmatizing post:\\n{example_style}\")\n",
    "\n",
    "# Also analyze the non-stigma post\n",
    "non_stigma_style = core.analyze_text_llm(text=DRUG_NON_STIGMA_POST, client=client, model=model)\n",
    "print(f\"\\nText style analysis for non-stigmatizing post:\\n{non_stigma_style}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rewriting Stigmatizing Content\n",
    "\n",
    "Let's rewrite stigmatizing content to be more neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Addicts really need to get control of themselves. Just stop doing drugs. It seems like these people are just lacking willpower.\n",
      "Rewritten: people struggling with substance use face complex challenges. recovery requires support, understanding, and access to resources.\n"
     ]
    }
   ],
   "source": [
    "# Get stigma classification for the example post\n",
    "example_post = DRUG_AND_STIGMA_POST\n",
    "example_stigma = core.classify_if_stigma(text=example_post, client=client, model=model)\n",
    "\n",
    "# Get text style for rewriting\n",
    "example_style_instruct = str(core.analyze_text_llm(text=example_post, client=client, model=model))\n",
    "\n",
    "# Rewrite the stigmatizing content\n",
    "rewritten_example = core.rewrite_to_destigma(\n",
    "    text=example_post,\n",
    "    explanation=example_stigma,\n",
    "    style_instruct=example_style_instruct,\n",
    "    model=model,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "print(f\"Original: {example_post}\")\n",
    "print(f\"Rewritten: {rewritten_example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Workflow Encapsulation\n",
    "\n",
    "Finally, you can also see how all the functions work together in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Classifying drug-related content...\n",
      "Text is not drug-related. Skipping further analysis.\n",
      "Original: Addicts really need to get control of themselves. Just stop doing drugs. It seems like these people are just lacking willpower.\n",
      "Rewritten: Addicts really need to get control of themselves. Just stop doing drugs. It seems like these people are just lacking willpower.\n"
     ]
    }
   ],
   "source": [
    "rewrote_text = core.analyze_and_rewrite_text(DRUG_AND_STIGMA_POST, client, model)\n",
    "print(f\"Original: {DRUG_AND_STIGMA_POST}\")\n",
    "print(f\"Rewritten: {rewrote_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've demonstrated the core functionality of the Reframe package:\n",
    "1. Classifying drug-related content\n",
    "2. Identifying stigmatizing language\n",
    "3. Analyzing text style\n",
    "4. Rewriting stigmatizing content to be more neutral while preserving the original message\n",
    "\n",
    "These tools can be used to analyze and improve communication about substance use disorders and reduce harmful stigma."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reframe-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
