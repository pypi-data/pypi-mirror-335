{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675897d0-0643-43d6-a950-203406025a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cea2d4f-7fec-45d4-8f80-2390ede7e7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2800b5fc-2b01-482d-b31e-658707d3a260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'study', 'for', 'NLP', '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text='I study for NLP.'\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608b0190-e144-494d-bbb7-db30fa0b0d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'strong', 'coffee', '.', 'It', 'is', 'very', 'strong', ',', 'and', 'I', 'like', 'strong', 'coffee', '.', 'Make', 'coffee', 'and', 'make', 'decision', '.', 'I', 'had', 'a', 'strong', 'feeling', 'about', 'that', '.']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "f=open(\"SAMPLETEXT.txt\",\"r\")\n",
    "text=f.read()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "word_tokens = word_tokenize(text)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "067bc2d4-ac1f-45eb-81e3-6add0bf9e29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'strong', 'coffee', 'It', 'strong', 'I', 'like', 'strong', 'coffee', 'Make', 'coffee', 'make', 'decision', 'I', 'strong', 'feeling']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = [word for word in word_tokens if (word not in stop_words and word not in string.punctuation)]\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d83fd510-bc70-4b36-b578-9ee7b279cd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter the critical value :  0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothesis rejected thus the given words(  This   strong  ) form a collocation\n",
      "0.75\n",
      "hypothesis rejected thus the given words(  strong   coffee  ) form a collocation\n",
      "0.8838834764831843\n",
      "hypothesis rejected thus the given words(  coffee   It  ) form a collocation\n",
      "0.8125\n",
      "hypothesis rejected thus the given words(  It   strong  ) form a collocation\n",
      "0.75\n",
      "hypothesis rejected thus the given words(  strong   I  ) form a collocation\n",
      "0.5\n",
      "hypothesis rejected thus the given words(  I   like  ) form a collocation\n",
      "0.875\n",
      "hypothesis rejected thus the given words(  like   strong  ) form a collocation\n",
      "0.75\n",
      "hypothesis rejected thus the given words(  strong   coffee  ) form a collocation\n",
      "0.8838834764831843\n",
      "hypothesis rejected thus the given words(  coffee   Make  ) form a collocation\n",
      "0.8125\n",
      "hypothesis rejected thus the given words(  Make   coffee  ) form a collocation\n",
      "0.8125\n",
      "hypothesis rejected thus the given words(  coffee   make  ) form a collocation\n",
      "0.8125\n",
      "hypothesis rejected thus the given words(  make   decision  ) form a collocation\n",
      "0.9375\n",
      "hypothesis rejected thus the given words(  decision   I  ) form a collocation\n",
      "0.875\n",
      "hypothesis rejected thus the given words(  I   strong  ) form a collocation\n",
      "0.5\n",
      "hypothesis rejected thus the given words(  strong   feeling  ) form a collocation\n",
      "0.75\n",
      "['This', 'strong', 0.75]\n",
      "['coffee', 'It', 0.8125]\n",
      "['It', 'strong', 0.75]\n",
      "['strong', 'I', 0.5]\n",
      "['I', 'like', 0.875]\n",
      "['like', 'strong', 0.75]\n",
      "['strong', 'coffee', 0.8838834764831843]\n",
      "['coffee', 'Make', 0.8125]\n",
      "['Make', 'coffee', 0.8125]\n",
      "['coffee', 'make', 0.8125]\n",
      "['make', 'decision', 0.9375]\n",
      "['decision', 'I', 0.875]\n",
      "['I', 'strong', 0.5]\n",
      "['strong', 'feeling', 0.75]\n"
     ]
    }
   ],
   "source": [
    "cv=input(\"enter the critical value : \")\n",
    "def collocation(w1,w2):\n",
    "    nl=list()\n",
    "    N=len(word_tokens)\n",
    "    pw1=word_tokens.count(w1)\n",
    "    pw2=word_tokens.count(w2)\n",
    "    md=((pw1/N)*(pw2/N))\n",
    "    j=0\n",
    "    for i in range(len(word_tokens)-1):\n",
    "        if(word_tokens[i]==w1 and word_tokens[i+1]==w2):\n",
    "            j=j+1\n",
    "    pw12=j\n",
    "    x=pw12/N\n",
    "    s2=x\n",
    "    t=(x-md)/(x/N)**0.5\n",
    "    if(float(t) > float(cv)):\n",
    "        print(\"hypothesis rejected thus the given words( \",w1,\" \",w2,\" ) form a collocation\")\n",
    "        print(t)\n",
    "        nl.append(w1)\n",
    "        nl.append(w2)\n",
    "        nl.append(t)\n",
    "    return nl\n",
    "fcol=[]\n",
    "for i in range(len(word_tokens)-1):\n",
    "    w1=word_tokens[i]\n",
    "    w2=word_tokens[i+1]\n",
    "    fcol.append(collocation(w1,w2))\n",
    "for i in fcol:\n",
    "    if(len(i) > 1):\n",
    "        if(fcol.count(i)>1):\n",
    "            fcol.remove(i)\n",
    "    else:\n",
    "        fcol.remove(i)\n",
    "for i in fcol:\n",
    "    if(len(i) > 1):\n",
    "        print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164ea7b8-1629-41c8-baa8-810e81503ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis rejected: the words (' strong ', ' coffee ') form a collocation.\n",
      "Chi-squared: 2.0\n",
      "Hypothesis rejected: the words (' strong ', ' like ') form a collocation.\n",
      "Chi-squared: 2.181818181818182\n",
      "Hypothesis rejected: the words (' like ', ' strong ') form a collocation.\n",
      "Chi-squared: 2.181818181818182\n",
      "Hypothesis rejected: the words (' strong ', ' coffee ') form a collocation.\n",
      "Chi-squared: 2.0\n",
      "Hypothesis rejected: the words (' coffee ', ' make ') form a collocation.\n",
      "Chi-squared: 7.2\n",
      "Hypothesis rejected: the words (' coffee ', ' make ') form a collocation.\n",
      "Chi-squared: 7.2\n",
      "Hypothesis rejected: the words (' make ', ' decision ') form a collocation.\n",
      "Chi-squared: 5.454545454545456\n",
      "Hypothesis rejected: the words (' decision ', ' strong ') form a collocation.\n",
      "Chi-squared: 2.181818181818182\n",
      "Hypothesis rejected: the words (' strong ', ' feeling ') form a collocation.\n",
      "Chi-squared: 2.181818181818182\n",
      "Collocations (with stopwords): [['strong', 'coffee', 2.0], ['strong', 'like', 2.181818181818182], ['like', 'strong', 2.181818181818182], ['coffee', 'make', 7.2], ['make', 'decision', 5.454545454545456], ['decision', 'strong', 2.181818181818182], ['strong', 'feeling', 2.181818181818182]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def collocation1(w1, w2, word_tokens, cv):\n",
    "    nl = []\n",
    "    N = len(word_tokens)\n",
    "    pw1 = word_tokens.count(w1)\n",
    "    pw2 = word_tokens.count(w2)\n",
    "    Ew1w2 = ((pw1 * pw2) / N)\n",
    "    Ew1nw2 = ((pw1 * (N - pw2)) / N)\n",
    "    Enw1w2 = (((N - pw1) * pw2) / N)\n",
    "    Enw1nw2 = (((N - pw1) * (N - pw2)) / N)\n",
    "    j = 0\n",
    "    for i in range(len(word_tokens) - 1):\n",
    "        if word_tokens[i] == w1 and word_tokens[i + 1] == w2:\n",
    "            j += 1\n",
    "    pw12 = j\n",
    "    Ow1w2 = pw12\n",
    "    Ow1nw2 = pw1 - pw12\n",
    "    Onw1w2 = pw2 - pw12\n",
    "    Onw1nw2 = N - (Ow1w2 + Ow1nw2 + Onw1w2)  # Corrected calculation\n",
    "    X = 0.0\n",
    "    if Ew1w2 != 0:\n",
    "        X += (((Ow1w2 - Ew1w2) ** 2) / Ew1w2)\n",
    "    if Ew1nw2 != 0:\n",
    "        X += (((Ow1nw2 - Ew1nw2) ** 2) / Ew1nw2)\n",
    "    if Enw1w2 != 0:\n",
    "        X += (((Onw1w2 - Enw1w2) ** 2) / Enw1w2)\n",
    "    if Enw1nw2 != 0:\n",
    "        X += (((Onw1nw2 - Enw1nw2) ** 2) / Enw1nw2)\n",
    "    if X > float(cv):\n",
    "        print(\"Hypothesis rejected: the words ('\", w1, \"', '\", w2, \"') form a collocation.\")\n",
    "        print(\"Chi-squared:\", X) \n",
    "        nl.append(w1)\n",
    "        nl.append(w2)\n",
    "        nl.append(X)\n",
    "    return nl\n",
    "\n",
    "def find_collocations(text, cv=1, remove_stopwords=True):\n",
    "    word_tokens = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = [w for w in word_tokens if w not in stop_words and w.isalnum()] # Also remove punctuation\n",
    "    fcol = []\n",
    "    for i in range(len(word_tokens) - 1):\n",
    "        w1 = word_tokens[i]\n",
    "        w2 = word_tokens[i + 1]\n",
    "        fcol.append(collocation1(w1, w2, word_tokens, cv))\n",
    "    filtered_fcol = []\n",
    "    for i in fcol:\n",
    "        if i and i not in filtered_fcol:\n",
    "            filtered_fcol.append(i)\n",
    "    return filtered_fcol\n",
    "text = \"This is a strong coffee. It is very strong, and I like strong coffee.  Make coffee and make decision.  I had a strong feeling about that.\"\n",
    "collocations_with_stopwords = find_collocations(text, remove_stopwords=False)\n",
    "print(\"Collocations (with stopwords):\", collocations_with_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c84676-83c5-44d4-97dc-d2dc89ee2d80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
