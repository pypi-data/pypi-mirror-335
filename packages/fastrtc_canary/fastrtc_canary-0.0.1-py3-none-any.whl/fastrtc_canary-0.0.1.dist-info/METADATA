Metadata-Version: 2.4
Name: fastrtc_canary
Version: 0.0.1
Summary: The realtime communication library for Python - fastrtc with Nvidia's Canary STT
Project-URL: repository, https://github.com/freddyaboulton/gradio-webrtc
Project-URL: issues, https://github.com/freddyaboulton/gradio-webrtc/issues
Project-URL: Documentation, https://freddyaboulton.github.io/gradio-webrtc/cookbook/
Author-email: Freddy Boulton <YOUREMAIL@domain.com>, Mahimai Raja <YOUREMAIL@domain.com>
License-Expression: Apache-2.0
License-File: LICENSE
Keywords: audio,audio processing,computer vision,gradio-custom-component,image,machine learning,realtime,streaming,video,video processing,webrtc
Classifier: Development Status :: 3 - Alpha
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Internet
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Visualization
Classifier: Topic :: Software Development
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Application Frameworks
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.10
Requires-Dist: aiortc
Requires-Dist: audioop-lts; python_version >= '3.13'
Requires-Dist: gradio<6.0,>=4.0
Requires-Dist: groq>=0.20.0
Requires-Dist: librosa
Requires-Dist: nemo-toolkit[asr]
Requires-Dist: numba>=0.60.0
Requires-Dist: numpy>=2.0.2
Requires-Dist: standard-aifc; python_version >= '3.13'
Requires-Dist: standard-sunau; python_version >= '3.13'
Provides-Extra: dev
Requires-Dist: build; extra == 'dev'
Requires-Dist: twine; extra == 'dev'
Provides-Extra: stopword
Requires-Dist: fastrtc-moonshine-onnx; extra == 'stopword'
Requires-Dist: onnxruntime>=1.20.1; extra == 'stopword'
Provides-Extra: stt
Requires-Dist: fastrtc-moonshine-onnx; extra == 'stt'
Requires-Dist: onnxruntime>=1.20.1; extra == 'stt'
Provides-Extra: tts
Requires-Dist: kokoro-onnx; extra == 'tts'
Provides-Extra: vad
Requires-Dist: onnxruntime>=1.20.1; extra == 'vad'
Description-Content-Type: text/markdown

<div style='text-align: center; margin-bottom: 1rem; display: flex; justify-content: center; align-items: center;'>
    <h1 style='color: white; margin: 0;'>FastRTC Canary</h1>
    <img src='https://huggingface.co/datasets/freddyaboulton/bucket/resolve/main/fastrtc_logo_small.png'
         alt="FastRTC Logo" 
         style="margin-right: 10px;">
</div>

<div style="display: flex; flex-direction: row; justify-content: center">
<img style="display: block; padding-right: 5px; height: 20px;" alt="Static Badge" src="https://img.shields.io/pypi/v/fastrtc_canary"> 
<a href="https://github.com/mahimairaja/fastrtc_canary" target="_blank"><img alt="Static Badge" src="https://img.shields.io/badge/github-white?logo=github&logoColor=black"></a>
</div>

<h3 style='text-align: center'>
The Real-Time Communication Library for Python with Canary STT
</h3>

Turn any python function into a real-time audio and video stream over WebRTC or WebSockets.

## Installation

### Assume you have fastrtc installed - [fastrtc](https://github.com/freddyaboulton/fastrtc)

```bash
pip install fastrtc_canary
```


## Features

- ðŸŽ¯ Direct integration with Nvidia's Canary STT model
- ðŸ”„ Seamless compatibility with all FastRTC features
- ðŸš€ Real-time audio transcription
- ðŸ”Œ Drop-in replacement for FastRTC's STT components

## Quick Start

```python
from fastrtc_canary import get_stt_model as get_stt_model_canary
from fastrtc import (ReplyOnPause, Stream, get_tts_model, list_stt_models)
from groq import Groq

print(f"Available STT models: {list_stt_models()}")  
# Available STT models: ['moonshine/base', 'moonshine/tiny', 'canary/1b']

client = Groq()
stt_model = get_stt_model_canary(
                        "canary/1b",
                        lang="en"  # Optional, defaults to "en"
                    )
tts_model = get_tts_model()

def echo(audio):
    prompt = stt_model.stt(audio)

    response = (
        client.chat.completions.create(
            model="llama-3.1-8b-instant",
            max_tokens=200,
            messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": prompt}
                ]
        )
        .choices[0]
        .message.content
    )

    for audio_chunk in tts_model.stream_tts_sync(response):
        yield audio_chunk

stream = Stream(ReplyOnPause(echo), modality="audio", mode="send-receive")

stream.ui.launch()
```

## Requirements

- Python >= 3.10
- FastRTC >= 0.0.14
- Groq >= 0.20.0

## Documentation

For more detailed information about the base FastRTC package, visit [https://fastrtc.org](https://fastrtc.org)

## License

MIT

