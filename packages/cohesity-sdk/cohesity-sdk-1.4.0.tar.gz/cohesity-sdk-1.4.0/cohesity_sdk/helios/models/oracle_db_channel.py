# coding: utf-8

"""
    Cohesity REST API

    Cohesity API provides a RESTful interface to access the various data management operations on Cohesity cluster and Helios.

    The version of the OpenAPI document: 2.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from cohesity_sdk.helios.models.credentials import Credentials
from cohesity_sdk.helios.models.oracle_database_host import OracleDatabaseHost
from typing import Set
from typing_extensions import Self

class OracleDbChannel(BaseModel):
    """
    Specifies the DB channel info for all the databases of app entity. Length of this array will be 1 for RAC and Standalone setups.
    """ # noqa: E501
    archive_log_retention_days: Optional[StrictInt] = Field(default=None, description="Specifies the number of days archive log should be stored. For keeping the archived log forever, set this to -1. For deleting the archived log immediately, set this to 0. For deleting the archived log after n days, set this to n.", alias="archiveLogRetentionDays")
    archive_log_retention_hours: Optional[StrictInt] = Field(default=None, description="Specifies the number of hours archive log should be stored. For keeping the archived log forever, set this to -1. For deleting the archived log immediately, set this to 0. For deleting the archived log after k hours, set this to k.", alias="archiveLogRetentionHours")
    credentials: Optional[Credentials] = None
    database_node_list: Optional[List[OracleDatabaseHost]] = Field(default=None, description="Specifies the Node info from where we are allowed to take the backup/restore.", alias="databaseNodeList")
    database_unique_name: Optional[StrictStr] = Field(default=None, description="Specifies the unique Name of the database.", alias="databaseUniqueName")
    database_uuid: Optional[StrictStr] = Field(default=None, description="Specifies the database unique id. This is an internal field and is filled by magneto master based on corresponding app entity id.", alias="databaseUuid")
    default_channel_count: Optional[StrictInt] = Field(default=None, description="Specifies the default number of channels to use per node per database. This value is used on all Oracle Database Nodes unless databaseNodeList item's channelCount is specified for the node. Default value for the number of channels will be calculated as the minimum of number of nodes in Cohesity cluster and 2 * number of CPU on the host. If the number of channels is unspecified here and unspecified within databaseNodeList, the above formula will be used to determine the same.", alias="defaultChannelCount")
    enable_dg_primary_backup: Optional[StrictBool] = Field(default=None, description="Specifies whether the database having the Primary role within Data Guard configuration is to be backed up.", alias="enableDgPrimaryBackup")
    max_host_count: Optional[StrictInt] = Field(default=None, description="Specifies the maximum number of hosts from which backup/restore is allowed in parallel. This will be less than or equal to the number of databaseNode specified within databaseNodeList.", alias="maxHostCount")
    rman_backup_type: Optional[StrictStr] = Field(default=None, description="Specifies the type of Oracle RMAN backup requested", alias="rmanBackupType")
    __properties: ClassVar[List[str]] = ["archiveLogRetentionDays", "archiveLogRetentionHours", "credentials", "databaseNodeList", "databaseUniqueName", "databaseUuid", "defaultChannelCount", "enableDgPrimaryBackup", "maxHostCount", "rmanBackupType"]

    @field_validator('rman_backup_type')
    def rman_backup_type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['kImageCopy', 'kBackupSets', 'kSbt']):
            raise ValueError("must be one of enum values ('kImageCopy', 'kBackupSets', 'kSbt')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of OracleDbChannel from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of credentials
        if self.credentials:
            _dict['credentials'] = self.credentials.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in database_node_list (list)
        _items = []
        if self.database_node_list:
            for _item_database_node_list in self.database_node_list:
                if _item_database_node_list:
                    _items.append(_item_database_node_list.to_dict())
            _dict['databaseNodeList'] = _items
        # set to None if archive_log_retention_days (nullable) is None
        # and model_fields_set contains the field
        if self.archive_log_retention_days is None and "archive_log_retention_days" in self.model_fields_set:
            _dict['archiveLogRetentionDays'] = None

        # set to None if archive_log_retention_hours (nullable) is None
        # and model_fields_set contains the field
        if self.archive_log_retention_hours is None and "archive_log_retention_hours" in self.model_fields_set:
            _dict['archiveLogRetentionHours'] = None

        # set to None if database_node_list (nullable) is None
        # and model_fields_set contains the field
        if self.database_node_list is None and "database_node_list" in self.model_fields_set:
            _dict['databaseNodeList'] = None

        # set to None if database_unique_name (nullable) is None
        # and model_fields_set contains the field
        if self.database_unique_name is None and "database_unique_name" in self.model_fields_set:
            _dict['databaseUniqueName'] = None

        # set to None if database_uuid (nullable) is None
        # and model_fields_set contains the field
        if self.database_uuid is None and "database_uuid" in self.model_fields_set:
            _dict['databaseUuid'] = None

        # set to None if default_channel_count (nullable) is None
        # and model_fields_set contains the field
        if self.default_channel_count is None and "default_channel_count" in self.model_fields_set:
            _dict['defaultChannelCount'] = None

        # set to None if enable_dg_primary_backup (nullable) is None
        # and model_fields_set contains the field
        if self.enable_dg_primary_backup is None and "enable_dg_primary_backup" in self.model_fields_set:
            _dict['enableDgPrimaryBackup'] = None

        # set to None if max_host_count (nullable) is None
        # and model_fields_set contains the field
        if self.max_host_count is None and "max_host_count" in self.model_fields_set:
            _dict['maxHostCount'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of OracleDbChannel from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "archiveLogRetentionDays": obj.get("archiveLogRetentionDays"),
            "archiveLogRetentionHours": obj.get("archiveLogRetentionHours"),
            "credentials": Credentials.from_dict(obj["credentials"]) if obj.get("credentials") is not None else None,
            "databaseNodeList": [OracleDatabaseHost.from_dict(_item) for _item in obj["databaseNodeList"]] if obj.get("databaseNodeList") is not None else None,
            "databaseUniqueName": obj.get("databaseUniqueName"),
            "databaseUuid": obj.get("databaseUuid"),
            "defaultChannelCount": obj.get("defaultChannelCount"),
            "enableDgPrimaryBackup": obj.get("enableDgPrimaryBackup"),
            "maxHostCount": obj.get("maxHostCount"),
            "rmanBackupType": obj.get("rmanBackupType")
        })
        return _obj


